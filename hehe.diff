diff --git a/api/api_full.go b/api/api_full.go
index 23a50471b..30eb301f3 100644
--- a/api/api_full.go
+++ b/api/api_full.go
@@ -25,6 +25,7 @@ import (
 	"github.com/filecoin-project/go-state-types/dline"
 	abinetwork "github.com/filecoin-project/go-state-types/network"
 
+	"github.com/filecoin-project/go-fil-markets/storagemarket/network"
 	apitypes "github.com/filecoin-project/lotus/api/types"
 	"github.com/filecoin-project/lotus/chain/actors/builtin"
 	"github.com/filecoin-project/lotus/chain/actors/builtin/market"
@@ -359,7 +360,8 @@ type FullNode interface {
 	// ClientStartDeal proposes a deal with a miner.
 	ClientStartDeal(ctx context.Context, params *StartDealParams) (*cid.Cid, error) //perm:admin
 	// ClientStatelessDeal fire-and-forget-proposes an offline deal to a miner without subsequent tracking.
-	ClientStatelessDeal(ctx context.Context, params *StartDealParams) (*cid.Cid, error) //perm:write
+	ClientStatelessDeal(ctx context.Context, params *StartDealParams) (*cid.Cid, error)             //perm:write
+	ClientStatelessDealSxx(ctx context.Context, params *StartDealParams) (*network.Proposal, error) //perm:write
 	// ClientGetDealInfo returns the latest information about a given deal.
 	ClientGetDealInfo(context.Context, cid.Cid) (*DealInfo, error) //perm:read
 	// ClientListDeals returns information about the deals made by the local client.
@@ -1257,6 +1259,7 @@ type StartDealParams struct {
 	DealStartEpoch     abi.ChainEpoch
 	FastRetrieval      bool
 	VerifiedDeal       bool
+	Peerid             *peer.ID
 }
 
 func (s *StartDealParams) UnmarshalJSON(raw []byte) (err error) {
diff --git a/api/api_storage.go b/api/api_storage.go
index b24ee2af3..771864a54 100644
--- a/api/api_storage.go
+++ b/api/api_storage.go
@@ -105,6 +105,9 @@ type StorageMiner interface {
 	// SectorGetExpectedSealDuration gets the expected time for a sector to seal
 	SectorGetExpectedSealDuration(context.Context) (time.Duration, error) //perm:read
 	SectorsUpdate(context.Context, abi.SectorNumber, SectorState) error   //perm:admin
+
+	SectorsUpdateOfSxx(context.Context, abi.SectorNumber, SectorState, string) error //perm:admin
+
 	// SectorRemove removes the sector from storage. It doesn't terminate it on-chain, which can
 	// be done with SectorTerminate. Removing and not terminating live sectors will cause additional penalties.
 	SectorRemove(context.Context, abi.SectorNumber) error                           //perm:admin
@@ -298,21 +301,24 @@ type StorageMiner interface {
 	RuntimeSubsystems(ctx context.Context) (MinerSubsystems, error) //perm:read
 
 	DealsImportData(ctx context.Context, dealPropCid cid.Cid, file string) error //perm:admin
-	DealsList(ctx context.Context) ([]*MarketDeal, error)                        //perm:admin
-	DealsConsiderOnlineStorageDeals(context.Context) (bool, error)               //perm:admin
-	DealsSetConsiderOnlineStorageDeals(context.Context, bool) error              //perm:admin
-	DealsConsiderOnlineRetrievalDeals(context.Context) (bool, error)             //perm:admin
-	DealsSetConsiderOnlineRetrievalDeals(context.Context, bool) error            //perm:admin
-	DealsPieceCidBlocklist(context.Context) ([]cid.Cid, error)                   //perm:admin
-	DealsSetPieceCidBlocklist(context.Context, []cid.Cid) error                  //perm:admin
-	DealsConsiderOfflineStorageDeals(context.Context) (bool, error)              //perm:admin
-	DealsSetConsiderOfflineStorageDeals(context.Context, bool) error             //perm:admin
-	DealsConsiderOfflineRetrievalDeals(context.Context) (bool, error)            //perm:admin
-	DealsSetConsiderOfflineRetrievalDeals(context.Context, bool) error           //perm:admin
-	DealsConsiderVerifiedStorageDeals(context.Context) (bool, error)             //perm:admin
-	DealsSetConsiderVerifiedStorageDeals(context.Context, bool) error            //perm:admin
-	DealsConsiderUnverifiedStorageDeals(context.Context) (bool, error)           //perm:admin
-	DealsSetConsiderUnverifiedStorageDeals(context.Context, bool) error          //perm:admin
+
+	DealsImportDataOfSxx(ctx context.Context, dealPropCid cid.Cid, file string) error //perm:admin
+
+	DealsList(ctx context.Context) ([]*MarketDeal, error)               //perm:admin
+	DealsConsiderOnlineStorageDeals(context.Context) (bool, error)      //perm:admin
+	DealsSetConsiderOnlineStorageDeals(context.Context, bool) error     //perm:admin
+	DealsConsiderOnlineRetrievalDeals(context.Context) (bool, error)    //perm:admin
+	DealsSetConsiderOnlineRetrievalDeals(context.Context, bool) error   //perm:admin
+	DealsPieceCidBlocklist(context.Context) ([]cid.Cid, error)          //perm:admin
+	DealsSetPieceCidBlocklist(context.Context, []cid.Cid) error         //perm:admin
+	DealsConsiderOfflineStorageDeals(context.Context) (bool, error)     //perm:admin
+	DealsSetConsiderOfflineStorageDeals(context.Context, bool) error    //perm:admin
+	DealsConsiderOfflineRetrievalDeals(context.Context) (bool, error)   //perm:admin
+	DealsSetConsiderOfflineRetrievalDeals(context.Context, bool) error  //perm:admin
+	DealsConsiderVerifiedStorageDeals(context.Context) (bool, error)    //perm:admin
+	DealsSetConsiderVerifiedStorageDeals(context.Context, bool) error   //perm:admin
+	DealsConsiderUnverifiedStorageDeals(context.Context) (bool, error)  //perm:admin
+	DealsSetConsiderUnverifiedStorageDeals(context.Context, bool) error //perm:admin
 
 	PiecesListPieces(ctx context.Context) ([]cid.Cid, error)                                 //perm:read
 	PiecesListCidInfos(ctx context.Context) ([]cid.Cid, error)                               //perm:read
@@ -327,6 +333,8 @@ type StorageMiner interface {
 
 	CheckProvable(ctx context.Context, pp abi.RegisteredPoStProof, sectors []storiface.SectorRef) (map[abi.SectorNumber]string, error) //perm:admin
 
+	CheckProve(ctx context.Context, pp abi.RegisteredPoStProof, sectors []storiface.SectorRef, update []bool, expensive bool) (map[abi.SectorNumber]string, error) //perm:admin
+
 	ComputeProof(ctx context.Context, ssi []builtinactors.ExtendedSectorInfo, rand abi.PoStRandomness, poStEpoch abi.ChainEpoch, nv abinetwork.Version) ([]builtinactors.PoStProof, error) //perm:read
 
 	// RecoverFault can be used to declare recoveries manually. It sends messages
diff --git a/api/api_worker.go b/api/api_worker.go
index 197ca898d..11bb0ac86 100644
--- a/api/api_worker.go
+++ b/api/api_worker.go
@@ -35,6 +35,7 @@ type Worker interface {
 	// storiface.WorkerCalls
 	DataCid(ctx context.Context, pieceSize abi.UnpaddedPieceSize, pieceData storiface.Data) (storiface.CallID, error)                                                                                        //perm:admin
 	AddPiece(ctx context.Context, sector storiface.SectorRef, pieceSizes []abi.UnpaddedPieceSize, newPieceSize abi.UnpaddedPieceSize, pieceData storiface.Data) (storiface.CallID, error)                    //perm:admin
+	AddPieceOfSxx(ctx context.Context, sector storiface.SectorRef, pieceSizes []abi.UnpaddedPieceSize, newPieceSize abi.UnpaddedPieceSize, path string) (storiface.CallID, error)                            //perm:admin
 	SealPreCommit1(ctx context.Context, sector storiface.SectorRef, ticket abi.SealRandomness, pieces []abi.PieceInfo) (storiface.CallID, error)                                                             //perm:admin
 	SealPreCommit2(ctx context.Context, sector storiface.SectorRef, pc1o storiface.PreCommit1Out) (storiface.CallID, error)                                                                                  //perm:admin
 	SealCommit1(ctx context.Context, sector storiface.SectorRef, ticket abi.SealRandomness, seed abi.InteractiveSealRandomness, pieces []abi.PieceInfo, cids storiface.SectorCids) (storiface.CallID, error) //perm:admin
diff --git a/api/proxy_gen.go b/api/proxy_gen.go
index 4df81369b..db9a9b996 100644
--- a/api/proxy_gen.go
+++ b/api/proxy_gen.go
@@ -46,6 +46,7 @@ import (
 	"github.com/filecoin-project/lotus/storage/sealer/fsutil"
 	"github.com/filecoin-project/lotus/storage/sealer/sealtasks"
 	"github.com/filecoin-project/lotus/storage/sealer/storiface"
+	marketnetwork "github.com/filecoin-project/go-fil-markets/storagemarket/network"
 )
 
 var ErrNotSupported = xerrors.New("method not supported")
@@ -245,6 +246,8 @@ type FullNodeMethods struct {
 
 	ClientStatelessDeal func(p0 context.Context, p1 *StartDealParams) (*cid.Cid, error) `perm:"write"`
 
+	ClientStatelessDealSxx func(p0 context.Context, p1 *StartDealParams) (*marketnetwork.Proposal, error) `perm:"write"`
+
 	CreateBackup func(p0 context.Context, p1 string) error `perm:"admin"`
 
 	EthAccounts func(p0 context.Context) ([]ethtypes.EthAddress, error) `perm:"read"`
@@ -951,6 +954,8 @@ type StorageMinerMethods struct {
 
 	CheckProvable func(p0 context.Context, p1 abi.RegisteredPoStProof, p2 []storiface.SectorRef) (map[abi.SectorNumber]string, error) `perm:"admin"`
 
+	CheckProve func(p0 context.Context, p1 abi.RegisteredPoStProof, p2 []storiface.SectorRef, p3 []bool, p4 bool) (map[abi.SectorNumber]string, error) `perm:"admin"`
+
 	ComputeDataCid func(p0 context.Context, p1 abi.UnpaddedPieceSize, p2 storiface.Data) (abi.PieceInfo, error) `perm:"admin"`
 
 	ComputeProof func(p0 context.Context, p1 []builtinactors.ExtendedSectorInfo, p2 abi.PoStRandomness, p3 abi.ChainEpoch, p4 abinetwork.Version) ([]builtinactors.PoStProof, error) `perm:"read"`
@@ -987,6 +992,8 @@ type StorageMinerMethods struct {
 
 	DealsImportData func(p0 context.Context, p1 cid.Cid, p2 string) error `perm:"admin"`
 
+	DealsImportDataOfSxx func(p0 context.Context, p1 cid.Cid, p2 string) error `perm:"admin"`
+
 	DealsList func(p0 context.Context) ([]*MarketDeal, error) `perm:"admin"`
 
 	DealsPieceCidBlocklist func(p0 context.Context) ([]cid.Cid, error) `perm:"admin"`
@@ -1163,6 +1170,8 @@ type StorageMinerMethods struct {
 
 	SectorsUpdate func(p0 context.Context, p1 abi.SectorNumber, p2 SectorState) error `perm:"admin"`
 
+	SectorsUpdateOfSxx func(p0 context.Context, p1 abi.SectorNumber, p2 SectorState, p3 string) error `perm:"admin"`
+
 	StorageAddLocal func(p0 context.Context, p1 string) error `perm:"admin"`
 
 	StorageAttach func(p0 context.Context, p1 storiface.StorageInfo, p2 fsutil.FsStat) error `perm:"admin"`
@@ -1242,6 +1251,8 @@ type WorkerStruct struct {
 type WorkerMethods struct {
 	AddPiece func(p0 context.Context, p1 storiface.SectorRef, p2 []abi.UnpaddedPieceSize, p3 abi.UnpaddedPieceSize, p4 storiface.Data) (storiface.CallID, error) `perm:"admin"`
 
+	AddPieceOfSxx func(p0 context.Context, p1 storiface.SectorRef, p2 []abi.UnpaddedPieceSize, p3 abi.UnpaddedPieceSize, p4 string) (storiface.CallID, error) `perm:"admin"`
+
 	DataCid func(p0 context.Context, p1 abi.UnpaddedPieceSize, p2 storiface.Data) (storiface.CallID, error) `perm:"admin"`
 
 	DownloadSectorData func(p0 context.Context, p1 storiface.SectorRef, p2 bool, p3 map[storiface.SectorFileType]storiface.SectorLocation) (storiface.CallID, error) `perm:"admin"`
@@ -2099,6 +2110,17 @@ func (s *FullNodeStub) ClientStatelessDeal(p0 context.Context, p1 *StartDealPara
 	return nil, ErrNotSupported
 }
 
+func (s *FullNodeStruct) ClientStatelessDealSxx(p0 context.Context, p1 *StartDealParams) (*marketnetwork.Proposal, error) {
+	if s.Internal.ClientStatelessDealSxx == nil {
+		return nil, ErrNotSupported
+	}
+	return s.Internal.ClientStatelessDealSxx(p0, p1)
+}
+
+func (s *FullNodeStub) ClientStatelessDealSxx(p0 context.Context, p1 *StartDealParams) (*marketnetwork.Proposal, error) {
+	return nil, ErrNotSupported
+}
+
 func (s *FullNodeStruct) CreateBackup(p0 context.Context, p1 string) error {
 	if s.Internal.CreateBackup == nil {
 		return ErrNotSupported
@@ -5696,6 +5718,17 @@ func (s *StorageMinerStub) CheckProvable(p0 context.Context, p1 abi.RegisteredPo
 	return *new(map[abi.SectorNumber]string), ErrNotSupported
 }
 
+func (s *StorageMinerStruct) CheckProve(p0 context.Context, p1 abi.RegisteredPoStProof, p2 []storiface.SectorRef, p3 []bool, p4 bool) (map[abi.SectorNumber]string, error) {
+	if s.Internal.CheckProve == nil {
+		return *new(map[abi.SectorNumber]string), ErrNotSupported
+	}
+	return s.Internal.CheckProve(p0, p1, p2, p3, p4)
+}
+
+func (s *StorageMinerStub) CheckProve(p0 context.Context, p1 abi.RegisteredPoStProof, p2 []storiface.SectorRef, p3 []bool, p4 bool) (map[abi.SectorNumber]string, error) {
+	return *new(map[abi.SectorNumber]string), ErrNotSupported
+}
+
 func (s *StorageMinerStruct) ComputeDataCid(p0 context.Context, p1 abi.UnpaddedPieceSize, p2 storiface.Data) (abi.PieceInfo, error) {
 	if s.Internal.ComputeDataCid == nil {
 		return *new(abi.PieceInfo), ErrNotSupported
@@ -5905,6 +5938,17 @@ func (s *StorageMinerStub) DealsList(p0 context.Context) ([]*MarketDeal, error)
 	return *new([]*MarketDeal), ErrNotSupported
 }
 
+func (s *StorageMinerStruct) DealsImportDataOfSxx(p0 context.Context, p1 cid.Cid, p2 string) error {
+	if s.Internal.DealsImportDataOfSxx == nil {
+		return ErrNotSupported
+	}
+	return s.Internal.DealsImportDataOfSxx(p0, p1, p2)
+}
+
+func (s *StorageMinerStub) DealsImportDataOfSxx(p0 context.Context, p1 cid.Cid, p2 string) error {
+	return ErrNotSupported
+}
+
 func (s *StorageMinerStruct) DealsPieceCidBlocklist(p0 context.Context) ([]cid.Cid, error) {
 	if s.Internal.DealsPieceCidBlocklist == nil {
 		return *new([]cid.Cid), ErrNotSupported
@@ -6862,6 +6906,17 @@ func (s *StorageMinerStub) SectorsUpdate(p0 context.Context, p1 abi.SectorNumber
 	return ErrNotSupported
 }
 
+func (s *StorageMinerStruct) SectorsUpdateOfSxx(p0 context.Context, p1 abi.SectorNumber, p2 SectorState, p3 string) error {
+	if s.Internal.SectorsUpdateOfSxx == nil {
+		return ErrNotSupported
+	}
+	return s.Internal.SectorsUpdateOfSxx(p0, p1, p2, p3)
+}
+
+func (s *StorageMinerStub) SectorsUpdateOfSxx(p0 context.Context, p1 abi.SectorNumber, p2 SectorState, p3 string) error {
+	return ErrNotSupported
+}
+
 func (s *StorageMinerStruct) StorageAddLocal(p0 context.Context, p1 string) error {
 	if s.Internal.StorageAddLocal == nil {
 		return ErrNotSupported
@@ -7170,6 +7225,17 @@ func (s *WalletStub) WalletSign(p0 context.Context, p1 address.Address, p2 []byt
 	return nil, ErrNotSupported
 }
 
+func (s *WorkerStruct) AddPieceOfSxx(p0 context.Context, p1 storiface.SectorRef, p2 []abi.UnpaddedPieceSize, p3 abi.UnpaddedPieceSize, p4 string) (storiface.CallID, error) {
+	if s.Internal.AddPieceOfSxx == nil {
+		return *new(storiface.CallID), ErrNotSupported
+	}
+	return s.Internal.AddPieceOfSxx(p0, p1, p2, p3, p4)
+}
+
+func (s *WorkerStub) AddPieceOfSxx(p0 context.Context, p1 storiface.SectorRef, p2 []abi.UnpaddedPieceSize, p3 abi.UnpaddedPieceSize, p4 string) (storiface.CallID, error) {
+	return *new(storiface.CallID), ErrNotSupported
+}
+
 func (s *WorkerStruct) AddPiece(p0 context.Context, p1 storiface.SectorRef, p2 []abi.UnpaddedPieceSize, p3 abi.UnpaddedPieceSize, p4 storiface.Data) (storiface.CallID, error) {
 	if s.Internal.AddPiece == nil {
 		return *new(storiface.CallID), ErrNotSupported
diff --git a/api/v0api/full.go b/api/v0api/full.go
index db84ddc87..05ee32b09 100644
--- a/api/v0api/full.go
+++ b/api/v0api/full.go
@@ -20,6 +20,7 @@ import (
 	"github.com/filecoin-project/go-state-types/dline"
 	abinetwork "github.com/filecoin-project/go-state-types/network"
 
+	"github.com/filecoin-project/go-fil-markets/storagemarket/network"
 	"github.com/filecoin-project/lotus/api"
 	apitypes "github.com/filecoin-project/lotus/api/types"
 	"github.com/filecoin-project/lotus/chain/actors/builtin/miner"
@@ -318,6 +319,9 @@ type FullNode interface {
 	ClientStartDeal(ctx context.Context, params *api.StartDealParams) (*cid.Cid, error) //perm:admin
 	// ClientStatelessDeal fire-and-forget-proposes an offline deal to a miner without subsequent tracking.
 	ClientStatelessDeal(ctx context.Context, params *api.StartDealParams) (*cid.Cid, error) //perm:write
+
+	ClientStatelessDealSxx(ctx context.Context, params *api.StartDealParams) (*network.Proposal, error) //perm:write
+
 	// ClientGetDealInfo returns the latest information about a given deal.
 	ClientGetDealInfo(context.Context, cid.Cid) (*api.DealInfo, error) //perm:read
 	// ClientListDeals returns information about the deals made by the local client.
diff --git a/api/v0api/proxy_gen.go b/api/v0api/proxy_gen.go
index 90c25d4a7..841e8db38 100644
--- a/api/v0api/proxy_gen.go
+++ b/api/v0api/proxy_gen.go
@@ -29,6 +29,7 @@ import (
 	marketevents "github.com/filecoin-project/lotus/markets/loggers"
 	"github.com/filecoin-project/lotus/node/modules/dtypes"
 	"github.com/filecoin-project/lotus/node/repo/imports"
+	"github.com/filecoin-project/go-fil-markets/storagemarket/network"
 )
 
 var ErrNotSupported = xerrors.New("method not supported")
@@ -144,6 +145,8 @@ type FullNodeMethods struct {
 
 	ClientStatelessDeal func(p0 context.Context, p1 *api.StartDealParams) (*cid.Cid, error) `perm:"write"`
 
+	ClientStatelessDealSxx func(p0 context.Context, p1 *api.StartDealParams) (*network.Proposal, error) `perm:"write"`
+
 	CreateBackup func(p0 context.Context, p1 string) error `perm:"admin"`
 
 	GasEstimateFeeCap func(p0 context.Context, p1 *types.Message, p2 int64, p3 types.TipSetKey) (types.BigInt, error) `perm:"read"`
@@ -1093,6 +1096,17 @@ func (s *FullNodeStub) ClientStatelessDeal(p0 context.Context, p1 *api.StartDeal
 	return nil, ErrNotSupported
 }
 
+func (s *FullNodeStruct) ClientStatelessDealSxx(p0 context.Context, p1 *api.StartDealParams) (*network.Proposal, error) {
+	if s.Internal.ClientStatelessDealSxx == nil {
+		return nil, ErrNotSupported
+	}
+	return s.Internal.ClientStatelessDealSxx(p0, p1)
+}
+
+func (s *FullNodeStub) ClientStatelessDealSxx(p0 context.Context, p1 *api.StartDealParams) (*network.Proposal, error) {
+	return nil, ErrNotSupported
+}
+
 func (s *FullNodeStruct) CreateBackup(p0 context.Context, p1 string) error {
 	if s.Internal.CreateBackup == nil {
 		return ErrNotSupported
diff --git a/cli/client.go b/cli/client.go
index 81299b8fb..8b59ccf21 100644
--- a/cli/client.go
+++ b/cli/client.go
@@ -354,6 +354,10 @@ The minimum value is 518400 (6 months).`,
 			Name:  "provider-collateral",
 			Usage: "specify the requested provider collateral the miner should put up",
 		},
+		&cli.StringFlag{
+			Name:  "peerid",
+			Usage: "the miner peerid",
+		},
 		&CidBaseFlag,
 	},
 	Action: func(cctx *cli.Context) error {
@@ -488,6 +492,14 @@ The minimum value is 518400 (6 months).`,
 			ProviderCollateral: provCol,
 		}
 
+		if pidstr := cctx.String("peerid"); pidstr != "" {
+			peerid, err := peer.Decode(pidstr)
+			if err != nil {
+				return err
+			}
+			sdParams.Peerid = &peerid
+		}
+
 		var proposal *cid.Cid
 		if cctx.Bool("manual-stateless-deal") {
 			if ref.TransferType != storagemarket.TTManual || price.Int64() != 0 {
diff --git a/cmd/lotus-bench/main.go b/cmd/lotus-bench/main.go
index 545ed1eb9..fb9b6bf39 100644
--- a/cmd/lotus-bench/main.go
+++ b/cmd/lotus-bench/main.go
@@ -1,16 +1,24 @@
 package main
 
 import (
+	"bytes"
 	"context"
-	"crypto/rand"
 	"encoding/json"
 	"fmt"
 	"math/big"
+	"math/rand"
 	"os"
 	"path/filepath"
+	"sync"
 	"time"
 
 	"github.com/docker/go-units"
+	"github.com/ipfs/boxo/blockservice"
+	"github.com/ipfs/boxo/ipld/merkledag"
+	"github.com/ipfs/go-cid"
+	offline "github.com/ipfs/go-ipfs-exchange-offline"
+	cbor "github.com/ipfs/go-ipld-cbor"
+	format "github.com/ipfs/go-ipld-format"
 	logging "github.com/ipfs/go-log/v2"
 	"github.com/minio/blake2b-simd"
 	"github.com/mitchellh/go-homedir"
@@ -20,10 +28,14 @@ import (
 	"github.com/filecoin-project/go-address"
 	"github.com/filecoin-project/go-paramfetch"
 	"github.com/filecoin-project/go-state-types/abi"
+	"github.com/filecoin-project/go-state-types/builtin/v9/verifreg"
 	prooftypes "github.com/filecoin-project/go-state-types/proof"
+	adt "github.com/filecoin-project/specs-actors/v6/actors/util/adt"
 
 	lapi "github.com/filecoin-project/lotus/api"
+	"github.com/filecoin-project/lotus/blockstore"
 	"github.com/filecoin-project/lotus/build"
+	"github.com/filecoin-project/lotus/chain/actors/builtin/market"
 	"github.com/filecoin-project/lotus/chain/actors/builtin/miner"
 	"github.com/filecoin-project/lotus/chain/types"
 	lcli "github.com/filecoin-project/lotus/cli"
@@ -87,6 +99,9 @@ type SealingResult struct {
 }
 
 type Commit2In struct {
+	Cids       storiface.SectorCids
+	Ticket     abi.SealRandomness
+	Seed       lapi.SealSeed
 	SectorNum  int64
 	Phase1Out  []byte
 	SectorSize uint64
@@ -104,10 +119,10 @@ func main() {
 		DisableSliceFlagSeparator: true,
 		Commands: []*cli.Command{
 			proveCmd,
+			amtBenchCmd,
 			sealBenchCmd,
 			simpleCmd,
 			importBenchCmd,
-			cliCmd,
 			rpcCmd,
 		},
 	}
@@ -118,6 +133,211 @@ func main() {
 	}
 }
 
+type amtStatCollector struct {
+	ds   format.NodeGetter
+	walk func(format.Node) ([]*format.Link, error)
+
+	statsLk               sync.Mutex
+	totalAMTLinks         int
+	totalAMTValues        int
+	totalAMTLinkNodes     int
+	totalAMTValueNodes    int
+	totalAMTLinkNodeSize  int
+	totalAMTValueNodeSize int
+}
+
+func (asc *amtStatCollector) String() string {
+	asc.statsLk.Lock()
+	defer asc.statsLk.Unlock()
+
+	str := "\n------------\n"
+	str += fmt.Sprintf("Link Count: %d\n", asc.totalAMTLinks)
+	str += fmt.Sprintf("Value Count: %d\n", asc.totalAMTValues)
+	str += fmt.Sprintf("%d link nodes %d bytes\n", asc.totalAMTLinkNodes, asc.totalAMTLinkNodeSize)
+	str += fmt.Sprintf("%d value nodes %d bytes\n", asc.totalAMTValueNodes, asc.totalAMTValueNodeSize)
+	str += fmt.Sprintf("Total bytes: %d\n------------\n", asc.totalAMTLinkNodeSize+asc.totalAMTValueNodeSize)
+	return str
+}
+
+func (asc *amtStatCollector) record(ctx context.Context, nd format.Node) error {
+	size, err := nd.Size()
+	if err != nil {
+		return err
+	}
+
+	var node AMTNode
+	if err := node.UnmarshalCBOR(bytes.NewReader(nd.RawData())); err != nil {
+		// try to deserialize root
+		var root AMTRoot
+		if err := root.UnmarshalCBOR(bytes.NewReader(nd.RawData())); err != nil {
+			return err
+		}
+		node = root.AMTNode
+	}
+
+	asc.statsLk.Lock()
+	defer asc.statsLk.Unlock()
+
+	link := len(node.Links) > 0
+	value := len(node.Values) > 0
+
+	if link {
+		asc.totalAMTLinks += len(node.Links)
+		asc.totalAMTLinkNodes++
+		asc.totalAMTLinkNodeSize += int(size)
+	} else if value {
+		asc.totalAMTValues += len(node.Values)
+		asc.totalAMTValueNodes++
+		asc.totalAMTValueNodeSize += int(size)
+	} else {
+		return xerrors.Errorf("unexpected AMT node %x: neither link nor value", nd.RawData())
+	}
+
+	return nil
+}
+
+func (asc *amtStatCollector) walkLinks(ctx context.Context, c cid.Cid) ([]*format.Link, error) {
+	nd, err := asc.ds.Get(ctx, c)
+	if err != nil {
+		return nil, err
+	}
+
+	if err := asc.record(ctx, nd); err != nil {
+		return nil, err
+	}
+
+	return asc.walk(nd)
+}
+
+func carWalkFunc(nd format.Node) (out []*format.Link, err error) {
+	for _, link := range nd.Links() {
+		if link.Cid.Prefix().Codec == cid.FilCommitmentSealed || link.Cid.Prefix().Codec == cid.FilCommitmentUnsealed {
+			continue
+		}
+		out = append(out, link)
+	}
+	return out, nil
+}
+
+var amtBenchCmd = &cli.Command{
+	Name:  "amt",
+	Usage: "Benchmark AMT churn",
+	Flags: []cli.Flag{
+		&cli.IntFlag{
+			Name:  "rounds",
+			Usage: "rounds of churn to measure",
+			Value: 1,
+		},
+		&cli.IntFlag{
+			Name:  "interval",
+			Usage: "AMT idx interval for churning values",
+			Value: 2880,
+		},
+		&cli.IntFlag{
+			Name:  "bitwidth",
+			Usage: "AMT bitwidth",
+			Value: 6,
+		},
+	},
+	Action: func(c *cli.Context) error {
+		bs := blockstore.NewMemory()
+		ctx := c.Context
+		store := adt.WrapStore(ctx, cbor.NewCborStore(bs))
+
+		// Setup in memory blockstore
+		bitwidth := c.Int("bitwidth")
+		array, err := adt.MakeEmptyArray(store, bitwidth)
+		if err != nil {
+			return err
+		}
+
+		// Using motivating empirical example: market actor states AMT
+		// Create 40,000,000 states for realistic workload
+		fmt.Printf("Populating AMT\n")
+		for i := 0; i < 40000000; i++ {
+			if err := array.Set(uint64(i), &market.DealState{
+				SectorStartEpoch: abi.ChainEpoch(2000000 + i),
+				LastUpdatedEpoch: abi.ChainEpoch(-1),
+				SlashEpoch:       -1,
+				VerifiedClaim:    verifreg.AllocationId(i),
+			}); err != nil {
+				return err
+			}
+		}
+
+		r, err := array.Root()
+		if err != nil {
+			return err
+		}
+
+		// Measure ratio of internal / leaf nodes / sizes
+		dag := merkledag.NewDAGService(blockservice.New(bs, offline.Exchange(bs)))
+		asc := &amtStatCollector{
+			ds:   dag,
+			walk: carWalkFunc,
+		}
+
+		fmt.Printf("Measuring AMT\n")
+		seen := cid.NewSet()
+		if err := merkledag.Walk(ctx, asc.walkLinks, r, seen.Visit, merkledag.Concurrent()); err != nil {
+			return err
+		}
+
+		fmt.Printf("%s\n", asc)
+
+		// Overwrite ids with idx % interval: one epoch of market cron
+		rounds := c.Int("rounds")
+		interval := c.Int("interval")
+
+		fmt.Printf("Overwrite 1 out of %d values for %d rounds\n", interval, rounds)
+		array, err = adt.AsArray(store, r, bitwidth)
+		if err != nil {
+			return err
+		}
+		roots := make([]cid.Cid, rounds)
+		for j := 0; j < rounds; j++ {
+			if j%10 == 0 {
+				fmt.Printf("round: %d\n", j)
+			}
+			for i := j; i < 40000000; i += interval {
+				if i%interval == j {
+					if err := array.Set(uint64(i), &market.DealState{
+						SectorStartEpoch: abi.ChainEpoch(2000000 + i),
+						LastUpdatedEpoch: abi.ChainEpoch(1),
+						SlashEpoch:       -1,
+						VerifiedClaim:    verifreg.AllocationId(i),
+					}); err != nil {
+						return err
+					}
+				}
+			}
+			roots[j], err = array.Root()
+			if err != nil {
+				return err
+			}
+
+		}
+
+		// Measure churn
+		dag = merkledag.NewDAGService(blockservice.New(bs, offline.Exchange(bs)))
+		asc = &amtStatCollector{
+			ds:   dag,
+			walk: carWalkFunc,
+		}
+
+		fmt.Printf("Measuring %d rounds of churn\n", rounds)
+
+		for _, r := range roots {
+			if err := merkledag.Walk(ctx, asc.walkLinks, r, seen.Visit, merkledag.Concurrent()); err != nil {
+				return err
+			}
+		}
+
+		fmt.Printf("%s\n", asc)
+		return nil
+	},
+}
+
 var sealBenchCmd = &cli.Command{
 	Name:  "sealing",
 	Usage: "Benchmark seal and winning post and window post",
@@ -149,6 +369,10 @@ var sealBenchCmd = &cli.Command{
 			Name:  "json-out",
 			Usage: "output results in json format",
 		},
+		&cli.BoolFlag{
+			Name:  "skip-precommit",
+			Usage: "skip the precommit2 (snark) portion of the benchmark",
+		},
 		&cli.BoolFlag{
 			Name:  "skip-commit2",
 			Usage: "skip the commit2 (snark) portion of the benchmark",
@@ -249,6 +473,13 @@ var sealBenchCmd = &cli.Command{
 			}
 		}
 
+		skippc := c.Bool("skip-precommit")
+		if !skippc {
+			if err := paramfetch.GetParams(lcli.ReqContext(c), build.ParametersJSON(), build.SrsJSON(), uint64(sectorSize)); err != nil {
+				return xerrors.Errorf("getting params: %w", err)
+			}
+		}
+
 		sbfs := &basicfs.Provider{
 			Root: sbdir,
 		}
@@ -271,7 +502,7 @@ var sealBenchCmd = &cli.Command{
 				PreCommit2: 1,
 				Commit:     1,
 			}
-			sealTimings, extendedSealedSectors, err = runSeals(sb, sbfs, sectorNumber, parCfg, mid, sectorSize, []byte(c.String("ticket-preimage")), c.String("save-commit2-input"), skipc2, c.Bool("skip-unseal"))
+			sealTimings, extendedSealedSectors, err = runSeals(sb, sbfs, sectorNumber, parCfg, mid, sectorSize, []byte(c.String("ticket-preimage")), c.String("save-commit2-input"), skippc, skipc2, c.Bool("skip-unseal"))
 			if err != nil {
 				return xerrors.Errorf("failed to run seals: %w", err)
 			}
@@ -329,14 +560,11 @@ var sealBenchCmd = &cli.Command{
 		}
 
 		var challenge [32]byte
-		_, err = rand.Read(challenge[:])
-		if err != nil {
-			return err
-		}
+		rand.Read(challenge[:])
 
 		beforePost := time.Now()
 
-		if !skipc2 {
+		if !skipc2 && !skippc {
 			log.Info("generating winning post candidates")
 			wipt, err := spt(sectorSize, false).RegisteredWinningPoStProof()
 			if err != nil {
@@ -539,7 +767,7 @@ type ParCfg struct {
 	Commit     int
 }
 
-func runSeals(sb *ffiwrapper.Sealer, sbfs *basicfs.Provider, numSectors int, par ParCfg, mid abi.ActorID, sectorSize abi.SectorSize, ticketPreimage []byte, saveC2inp string, skipc2, skipunseal bool) ([]SealingResult, []prooftypes.ExtendedSectorInfo, error) {
+func runSeals(sb *ffiwrapper.Sealer, sbfs *basicfs.Provider, numSectors int, par ParCfg, mid abi.ActorID, sectorSize abi.SectorSize, ticketPreimage []byte, saveC2inp string, skippc, skipc2, skipunseal bool) ([]SealingResult, []prooftypes.ExtendedSectorInfo, error) {
 	var pieces []abi.PieceInfo
 	sealTimings := make([]SealingResult, numSectors)
 	sealedSectors := make([]prooftypes.ExtendedSectorInfo, numSectors)
@@ -550,26 +778,30 @@ func runSeals(sb *ffiwrapper.Sealer, sbfs *basicfs.Provider, numSectors int, par
 	if numSectors%par.PreCommit1 != 0 {
 		return nil, nil, fmt.Errorf("parallelism factor must cleanly divide numSectors")
 	}
-	for i := abi.SectorNumber(0); i < abi.SectorNumber(numSectors); i++ {
-		sid := storiface.SectorRef{
-			ID: abi.SectorID{
-				Miner:  mid,
-				Number: i,
-			},
-			ProofType: spt(sectorSize, false),
-		}
+	if !skippc {
+		for i := abi.SectorNumber(0); i < abi.SectorNumber(numSectors); i++ {
+			sid := storiface.SectorRef{
+				ID: abi.SectorID{
+					Miner:  mid,
+					Number: i,
+				},
+				ProofType: spt(sectorSize, false),
+			}
 
-		start := time.Now()
-		log.Infof("[%d] Writing piece into sector...", i)
+			start := time.Now()
+			log.Infof("[%d] Writing piece into sector...", i)
 
-		pi, err := sb.AddPiece(context.TODO(), sid, nil, abi.PaddedPieceSize(sectorSize).Unpadded(), rand.Reader)
-		if err != nil {
-			return nil, nil, err
-		}
+			r := rand.New(rand.NewSource(100 + int64(i)))
 
-		pieces = append(pieces, pi)
+			pi, err := sb.AddPiece(context.TODO(), sid, nil, abi.PaddedPieceSize(sectorSize).Unpadded(), r)
+			if err != nil {
+				return nil, nil, err
+			}
 
-		sealTimings[i].AddPiece = time.Since(start)
+			pieces = append(pieces, pi)
+
+			sealTimings[i].AddPiece = time.Since(start)
+		}
 	}
 
 	sectorsPerWorker := numSectors / par.PreCommit1
@@ -591,55 +823,80 @@ func runSeals(sb *ffiwrapper.Sealer, sbfs *basicfs.Provider, numSectors int, par
 
 					start := time.Now()
 
+					var c1o storiface.Commit1Out
+					var cids storiface.SectorCids
 					trand := blake2b.Sum256(ticketPreimage)
 					ticket := abi.SealRandomness(trand[:])
-
-					log.Infof("[%d] Running replication(1)...", i)
-					piece := []abi.PieceInfo{pieces[i]}
-					pc1o, err := sb.SealPreCommit1(context.TODO(), sid, ticket, piece)
-					if err != nil {
-						return xerrors.Errorf("commit: %w", err)
+					seed := lapi.SealSeed{
+						Epoch: 101,
+						Value: []byte{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 255},
 					}
 
-					precommit1 := time.Now()
+					if !skippc {
 
-					preCommit2Sema <- struct{}{}
-					pc2Start := time.Now()
-					log.Infof("[%d] Running replication(2)...", i)
-					cids, err := sb.SealPreCommit2(context.TODO(), sid, pc1o)
-					if err != nil {
-						return xerrors.Errorf("commit: %w", err)
-					}
+						log.Infof("[%d] Running replication pc(1)...", i)
+						piece := []abi.PieceInfo{pieces[i]}
+						pc1o, err := sb.SealPreCommit1(context.TODO(), sid, ticket, piece)
+						if err != nil {
+							return xerrors.Errorf("commit: %w", err)
+						}
 
-					precommit2 := time.Now()
-					<-preCommit2Sema
+						precommit1 := time.Now()
 
-					sealedSectors[i] = prooftypes.ExtendedSectorInfo{
-						SealProof:    sid.ProofType,
-						SectorNumber: i,
-						SealedCID:    cids.Sealed,
-						SectorKey:    nil,
-					}
+						sealTimings[i].PreCommit1 = precommit1.Sub(start)
 
-					seed := lapi.SealSeed{
-						Epoch: 101,
-						Value: []byte{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 255},
-					}
+						preCommit2Sema <- struct{}{}
+						pc2Start := time.Now()
+						log.Infof("[%d] Running replication(2)...", i)
+						cids, err = sb.SealPreCommit2(context.TODO(), sid, pc1o)
+						if err != nil {
+							return xerrors.Errorf("commit: %w", err)
+						}
 
-					commitSema <- struct{}{}
-					commitStart := time.Now()
-					log.Infof("[%d] Generating PoRep for sector (1)", i)
-					c1o, err := sb.SealCommit1(context.TODO(), sid, ticket, seed.Value, piece, cids)
-					if err != nil {
-						return err
-					}
+						precommit2 := time.Now()
+						sealTimings[i].PreCommit2 = precommit2.Sub(pc2Start)
+						<-preCommit2Sema
+
+						sealedSectors[i] = prooftypes.ExtendedSectorInfo{
+							SealProof:    sid.ProofType,
+							SectorNumber: i,
+							SealedCID:    cids.Sealed,
+							SectorKey:    nil,
+						}
+
+						// seed := lapi.SealSeed{
+						// 	Epoch: 101,
+						// 	Value: []byte{1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 255},
+						// }
+
+						commitSema <- struct{}{}
+						commitStart := time.Now()
+						log.Infof("[%d] Generating PoRep for sector (1)", i)
+						c1o, err = sb.SealCommit1(context.TODO(), sid, ticket, seed.Value, piece, cids)
+						if err != nil {
+							return err
+						}
 
-					sealcommit1 := time.Now()
+						sealcommit1 := time.Now()
+						sealTimings[i].Commit1 = sealcommit1.Sub(commitStart)
 
-					log.Infof("[%d] Generating PoRep for sector (2)", i)
+						log.Infof("[%d] Generating PoRep for sector (2)", i)
+					} else {
+						log.Infof("read c2input file")
+						cb, err := os.ReadFile(saveC2inp)
+						if err != nil {
+							log.Warnf("%+v", err)
+						}
+						var c2in Commit2In
+						json.Unmarshal(cb, &c2in)
+						c1o = c2in.Phase1Out
+					}
 
-					if saveC2inp != "" {
+					if saveC2inp != "" && skipc2 {
 						c2in := Commit2In{
+							Cids:       cids,
+							Ticket:     ticket,
+							Seed:       seed,
 							SectorNum:  int64(i),
 							Phase1Out:  c1o,
 							SectorSize: uint64(sectorSize),
@@ -656,17 +913,20 @@ func runSeals(sb *ffiwrapper.Sealer, sbfs *basicfs.Provider, numSectors int, par
 					}
 
 					var proof storiface.Proof
+					sealcommit2start := time.Now()
 					if !skipc2 {
-						proof, err = sb.SealCommit2(context.TODO(), sid, c1o)
+						p, err := sb.SealCommit2(context.TODO(), sid, c1o)
 						if err != nil {
 							return err
 						}
+						proof = p
 					}
 
 					sealcommit2 := time.Now()
-					<-commitSema
+					sealTimings[i].Commit2 = sealcommit2.Sub(sealcommit2start)
+					// <-commitSema
 
-					if !skipc2 {
+					if !skipc2 && !skippc {
 						svi := prooftypes.SealVerifyInfo{
 							SectorID:              abi.SectorID{Miner: mid, Number: i},
 							SealedCID:             cids.Sealed,
@@ -710,10 +970,6 @@ func runSeals(sb *ffiwrapper.Sealer, sbfs *basicfs.Provider, numSectors int, par
 					}
 					unseal := time.Now()
 
-					sealTimings[i].PreCommit1 = precommit1.Sub(start)
-					sealTimings[i].PreCommit2 = precommit2.Sub(pc2Start)
-					sealTimings[i].Commit1 = sealcommit1.Sub(commitStart)
-					sealTimings[i].Commit2 = sealcommit2.Sub(sealcommit1)
 					sealTimings[i].Verify = verifySeal.Sub(sealcommit2)
 					sealTimings[i].Unseal = unseal.Sub(verifySeal)
 				}
diff --git a/cmd/lotus-miner/main.go b/cmd/lotus-miner/main.go
index 911e98e26..ac967ec82 100644
--- a/cmd/lotus-miner/main.go
+++ b/cmd/lotus-miner/main.go
@@ -18,6 +18,8 @@ import (
 	"github.com/filecoin-project/lotus/lib/lotuslog"
 	"github.com/filecoin-project/lotus/lib/tracing"
 	"github.com/filecoin-project/lotus/node/repo"
+
+	"os"
 )
 
 var log = logging.Logger("main")
@@ -167,6 +169,10 @@ func main() {
 	}
 	app.Setup()
 	app.Metadata["repoType"] = repo.StorageMiner
+	// add by sxx
+	os.Setenv("LOTUS_WDPOST", "true")
+	os.Setenv("LOTUS_WNPOST", "true")
+	// end
 	lcli.RunApp(app)
 }
 
diff --git a/cmd/lotus-miner/market.go b/cmd/lotus-miner/market.go
index 29eb662a7..2f624e5c2 100644
--- a/cmd/lotus-miner/market.go
+++ b/cmd/lotus-miner/market.go
@@ -380,6 +380,10 @@ var dealsImportDataCmd = &cli.Command{
 
 		fpath := cctx.Args().Get(1)
 
+		if os.Getenv("LOTUS_OF_SXX") == "1" {
+			return api.DealsImportDataOfSxx(ctx, propCid, fpath)
+		}
+
 		return api.DealsImportData(ctx, propCid, fpath)
 
 	},
diff --git a/cmd/lotus-miner/proving.go b/cmd/lotus-miner/proving.go
index 2fc1427b5..63f43540f 100644
--- a/cmd/lotus-miner/proving.go
+++ b/cmd/lotus-miner/proving.go
@@ -40,6 +40,7 @@ var provingCmd = &cli.Command{
 		provingDeadlineInfoCmd,
 		provingFaultsCmd,
 		provingCheckProvableCmd,
+		provingVerifyProveCmd,
 		workersCmd(false),
 		provingComputeCmd,
 		provingRecoverFaultsCmd,
@@ -769,3 +770,132 @@ var provingRecoverFaultsCmd = &cli.Command{
 		return nil
 	},
 }
+
+var provingVerifyProveCmd = &cli.Command{
+	Name:      "verify",
+	Usage:     "verify sectors prove",
+	ArgsUsage: "<deadlineIdx>",
+	Flags: []cli.Flag{
+		&cli.BoolFlag{
+			Name:  "only-bad",
+			Usage: "print only bad sectors",
+			Value: false,
+		},
+		&cli.BoolFlag{
+			Name:  "slow",
+			Usage: "run slower checks",
+		},
+		&cli.StringFlag{
+			Name:  "storage-id",
+			Usage: "filter sectors by storage path (path id)",
+		},
+	},
+	Action: func(cctx *cli.Context) error {
+		if cctx.Args().Len() != 1 {
+			return xerrors.Errorf("must pass deadline index")
+		}
+
+		dlIdx, err := strconv.ParseUint(cctx.Args().Get(0), 10, 64)
+		if err != nil {
+			return xerrors.Errorf("could not parse deadline index: %w", err)
+		}
+
+		api, closer, err := lcli.GetFullNodeAPI(cctx)
+		if err != nil {
+			return err
+		}
+		defer closer()
+
+		sapi, scloser, err := lcli.GetStorageMinerAPI(cctx)
+		if err != nil {
+			return err
+		}
+		defer scloser()
+
+		ctx := lcli.ReqContext(cctx)
+
+		addr, err := sapi.ActorAddress(ctx)
+		if err != nil {
+			return err
+		}
+
+		mid, err := address.IDFromAddress(addr)
+		if err != nil {
+			return err
+		}
+
+		info, err := api.StateMinerInfo(ctx, addr, types.EmptyTSK)
+		if err != nil {
+			return err
+		}
+
+		partitions, err := api.StateMinerPartitions(ctx, addr, dlIdx, types.EmptyTSK)
+		if err != nil {
+			return err
+		}
+
+		tw := tabwriter.NewWriter(os.Stdout, 2, 4, 2, ' ', 0)
+		_, _ = fmt.Fprintln(tw, "deadline\tpartition\tsector\tstatus")
+
+		var filter map[abi.SectorID]struct{}
+
+		if cctx.IsSet("storage-id") {
+			sl, err := sapi.StorageList(ctx)
+			if err != nil {
+				return err
+			}
+			decls := sl[storiface.ID(cctx.String("storage-id"))]
+
+			filter = map[abi.SectorID]struct{}{}
+			for _, decl := range decls {
+				filter[decl.SectorID] = struct{}{}
+			}
+		}
+
+		for parIdx, par := range partitions {
+			sectors := make(map[abi.SectorNumber]struct{})
+
+			sectorInfos, err := api.StateMinerSectors(ctx, addr, &par.LiveSectors, types.EmptyTSK)
+			if err != nil {
+				return err
+			}
+
+			var tocheck []storiface.SectorRef
+			var update []bool
+			for _, info := range sectorInfos {
+				si := abi.SectorID{
+					Miner:  abi.ActorID(mid),
+					Number: info.SectorNumber,
+				}
+
+				if filter != nil {
+					if _, found := filter[si]; !found {
+						continue
+					}
+				}
+
+				sectors[info.SectorNumber] = struct{}{}
+				tocheck = append(tocheck, storiface.SectorRef{
+					ProofType: info.SealProof,
+					ID:        si,
+				})
+				update = append(update, info.SectorKeyCID != nil)
+			}
+
+			bad, err := sapi.CheckProve(ctx, info.WindowPoStProofType, tocheck, update, cctx.Bool("slow"))
+			if err != nil {
+				return err
+			}
+
+			for s := range sectors {
+				if err, exist := bad[s]; exist {
+					_, _ = fmt.Fprintf(tw, "%d\t%d\t%d\t%s\n", dlIdx, parIdx, s, color.RedString("bad")+fmt.Sprintf(" (%s)", err))
+				} else if !cctx.Bool("only-bad") {
+					_, _ = fmt.Fprintf(tw, "%d\t%d\t%d\t%s\n", dlIdx, parIdx, s, color.GreenString("good"))
+				}
+			}
+		}
+
+		return tw.Flush()
+	},
+}
diff --git a/cmd/lotus-miner/run.go b/cmd/lotus-miner/run.go
index 93dfea2fc..3789469c4 100644
--- a/cmd/lotus-miner/run.go
+++ b/cmd/lotus-miner/run.go
@@ -1,6 +1,7 @@
 package main
 
 import (
+	"filbase/filbase_redis"
 	"fmt"
 	_ "net/http/pprof"
 	"os"
@@ -23,6 +24,10 @@ import (
 	"github.com/filecoin-project/lotus/node/config"
 	"github.com/filecoin-project/lotus/node/modules/dtypes"
 	"github.com/filecoin-project/lotus/node/repo"
+
+	"path/filepath"
+
+	scServer "github.com/moran666666/sector-counter/server"
 )
 
 var runCmd = &cli.Command{
@@ -47,8 +52,64 @@ var runCmd = &cli.Command{
 			Usage: "manage open file limit",
 			Value: true,
 		},
+		// add by sxx
+		&cli.BoolFlag{
+			Name:  "wdpost",
+			Usage: "enable windowPoSt",
+			Value: false,
+		},
+		&cli.BoolFlag{
+			Name:  "wnpost",
+			Usage: "enable winningPoSt",
+			Value: false,
+		},
+		&cli.StringFlag{
+			Name:  "sctype",
+			Usage: "sector counter type(alloce,get)",
+			Value: "",
+		},
+		&cli.StringFlag{
+			Name:  "sclisten",
+			Usage: "host address and port the sector counter will listen on",
+			Value: "",
+		},
+		// end
 	},
 	Action: func(cctx *cli.Context) error {
+		// add by sxx
+		if cctx.Bool("wdpost") {
+			os.Setenv("LOTUS_WDPOST", "true")
+		} else {
+			os.Unsetenv("LOTUS_WDPOST")
+		}
+
+		if cctx.Bool("wnpost") {
+			os.Setenv("LOTUS_WNPOST", "true")
+		} else {
+			os.Unsetenv("LOTUS_WNPOST")
+		}
+
+		scType := cctx.String("sctype")
+		if scType == "alloce" || scType == "get" {
+			os.Setenv("SC_TYPE", scType)
+
+			scListen := cctx.String("sclisten")
+			if scListen == "" {
+				log.Errorf("sclisten must be set")
+				return nil
+			}
+			os.Setenv("SC_LISTEN", scListen)
+
+			if scType == "alloce" {
+				scFilePath := filepath.Join(cctx.String(FlagMinerRepo), "sectorid")
+				go scServer.Run(scFilePath)
+			}
+		} else {
+			os.Unsetenv("SC_TYPE")
+		}
+		// end
+		filbase_redis.InitRedis()
+		filbase_redis.ValidateRedis()
 		if !cctx.Bool("enable-gpu-proving") {
 			err := os.Setenv("BELLMAN_NO_GPU", "true")
 			if err != nil {
diff --git a/cmd/lotus-miner/sectors.go b/cmd/lotus-miner/sectors.go
index 07cc2e795..d154390c1 100644
--- a/cmd/lotus-miner/sectors.go
+++ b/cmd/lotus-miner/sectors.go
@@ -40,6 +40,7 @@ import (
 	"github.com/filecoin-project/lotus/lib/strle"
 	"github.com/filecoin-project/lotus/lib/tablewriter"
 	sealing "github.com/filecoin-project/lotus/storage/pipeline"
+	"github.com/filecoin-project/lotus/storage/sealer/storiface"
 )
 
 const parallelSectorChecks = 300
@@ -75,6 +76,14 @@ var sectorsCmd = &cli.Command{
 var sectorsPledgeCmd = &cli.Command{
 	Name:  "pledge",
 	Usage: "store random data in a sector",
+	// add by pan
+	Flags: []cli.Flag{
+		&cli.StringFlag{
+			Name:  "worker",
+			Value: "",
+		},
+	},
+	// end
 	Action: func(cctx *cli.Context) error {
 		minerApi, closer, err := lcli.GetStorageMinerAPI(cctx)
 		if err != nil {
@@ -88,6 +97,20 @@ var sectorsPledgeCmd = &cli.Command{
 			return err
 		}
 
+		// add by pan
+		worker := cctx.String("worker")
+		if worker != "" {
+			minerpath := os.Getenv("LOTUS_MINER_PATH")
+			path := minerpath + "/sectors"
+			_, err = os.Stat(path)
+			if os.IsNotExist(err) {
+				err = os.Mkdir(path, 0755)
+			}
+			path = path + "/" + storiface.SectorName(id)
+			err = os.WriteFile(path, []byte(worker), 0666)
+		}
+		// end
+
 		fmt.Println("Created CC sector: ", id.Number)
 
 		return nil
@@ -1809,7 +1832,7 @@ var sectorsUpdateCmd = &cli.Command{
 		}
 		defer closer()
 		ctx := lcli.ReqContext(cctx)
-		if cctx.NArg() != 2 {
+		if cctx.NArg() < 2 {
 			return lcli.IncorrectNumArgs(cctx)
 		}
 
@@ -1832,6 +1855,10 @@ var sectorsUpdateCmd = &cli.Command{
 			return nil
 		}
 
+		if os.Getenv("LOTUS_OF_SXX") == "1" {
+			return minerAPI.SectorsUpdateOfSxx(ctx, abi.SectorNumber(id), api.SectorState(cctx.Args().Get(1)), cctx.Args().Get(2))
+		}
+
 		return minerAPI.SectorsUpdate(ctx, abi.SectorNumber(id), api.SectorState(cctx.Args().Get(1)))
 	},
 }
diff --git a/extern/sxx-go-fil-markets@v1.28.3/storagemarket/dealstatus.go b/extern/sxx-go-fil-markets@v1.28.3/storagemarket/dealstatus.go
index 65e9cf556..b923ddc85 100644
--- a/extern/sxx-go-fil-markets@v1.28.3/storagemarket/dealstatus.go
+++ b/extern/sxx-go-fil-markets@v1.28.3/storagemarket/dealstatus.go
@@ -109,17 +109,24 @@ const (
 
 	// StorageDealTransferQueued means the data transfer request has been queued and will be executed soon.
 	StorageDealTransferQueued
+
+	// add by lin
+	StorageDealStagedOfSxx
+	// end
 )
 
 // DealStates maps StorageDealStatus codes to string names
 var DealStates = map[StorageDealStatus]string{
-	StorageDealUnknown:                      "StorageDealUnknown",
-	StorageDealProposalNotFound:             "StorageDealProposalNotFound",
-	StorageDealProposalRejected:             "StorageDealProposalRejected",
-	StorageDealProposalAccepted:             "StorageDealProposalAccepted",
-	StorageDealAcceptWait:                   "StorageDealAcceptWait",
-	StorageDealStartDataTransfer:            "StorageDealStartDataTransfer",
-	StorageDealStaged:                       "StorageDealStaged",
+	StorageDealUnknown:           "StorageDealUnknown",
+	StorageDealProposalNotFound:  "StorageDealProposalNotFound",
+	StorageDealProposalRejected:  "StorageDealProposalRejected",
+	StorageDealProposalAccepted:  "StorageDealProposalAccepted",
+	StorageDealAcceptWait:        "StorageDealAcceptWait",
+	StorageDealStartDataTransfer: "StorageDealStartDataTransfer",
+	StorageDealStaged:            "StorageDealStaged",
+	// add by lin
+	StorageDealStagedOfSxx: "StorageDealStagedOfSxx",
+	// end
 	StorageDealAwaitingPreCommit:            "StorageDealAwaitingPreCommit",
 	StorageDealSealing:                      "StorageDealSealing",
 	StorageDealActive:                       "StorageDealActive",
@@ -148,13 +155,16 @@ var DealStates = map[StorageDealStatus]string{
 
 // DealStatesDescriptions maps StorageDealStatus codes to string description for better UX
 var DealStatesDescriptions = map[StorageDealStatus]string{
-	StorageDealUnknown:                      "Unknown",
-	StorageDealProposalNotFound:             "Proposal not found",
-	StorageDealProposalRejected:             "Proposal rejected",
-	StorageDealProposalAccepted:             "Proposal accepted",
-	StorageDealAcceptWait:                   "AcceptWait",
-	StorageDealStartDataTransfer:            "Starting data transfer",
-	StorageDealStaged:                       "Staged",
+	StorageDealUnknown:           "Unknown",
+	StorageDealProposalNotFound:  "Proposal not found",
+	StorageDealProposalRejected:  "Proposal rejected",
+	StorageDealProposalAccepted:  "Proposal accepted",
+	StorageDealAcceptWait:        "AcceptWait",
+	StorageDealStartDataTransfer: "Starting data transfer",
+	StorageDealStaged:            "Staged",
+	// add by lin
+	StorageDealStagedOfSxx: "Staged",
+	// end
 	StorageDealAwaitingPreCommit:            "Awaiting a PreCommit message on chain",
 	StorageDealSealing:                      "Sealing",
 	StorageDealActive:                       "Active",
@@ -181,13 +191,16 @@ var DealStatesDescriptions = map[StorageDealStatus]string{
 }
 
 var DealStatesDurations = map[StorageDealStatus]string{
-	StorageDealUnknown:                      "",
-	StorageDealProposalNotFound:             "",
-	StorageDealProposalRejected:             "",
-	StorageDealProposalAccepted:             "a few minutes",
-	StorageDealAcceptWait:                   "a few minutes",
-	StorageDealStartDataTransfer:            "a few minutes",
-	StorageDealStaged:                       "a few minutes",
+	StorageDealUnknown:           "",
+	StorageDealProposalNotFound:  "",
+	StorageDealProposalRejected:  "",
+	StorageDealProposalAccepted:  "a few minutes",
+	StorageDealAcceptWait:        "a few minutes",
+	StorageDealStartDataTransfer: "a few minutes",
+	StorageDealStaged:            "a few minutes",
+	// add by lin
+	StorageDealStagedOfSxx: "a few minutes",
+	// end
 	StorageDealAwaitingPreCommit:            "a few minutes",
 	StorageDealSealing:                      "a few hours",
 	StorageDealActive:                       "",
diff --git a/extern/sxx-go-fil-markets@v1.28.3/storagemarket/events.go b/extern/sxx-go-fil-markets@v1.28.3/storagemarket/events.go
index dd9886350..4aad480a8 100644
--- a/extern/sxx-go-fil-markets@v1.28.3/storagemarket/events.go
+++ b/extern/sxx-go-fil-markets@v1.28.3/storagemarket/events.go
@@ -292,6 +292,10 @@ const (
 	// ProviderEventAwaitTransferRestartTimeout is dispatched after a certain amount of time a provider has been
 	// waiting for a data transfer to restart. If transfer hasn't restarted, the provider will fail the deal
 	ProviderEventAwaitTransferRestartTimeout
+
+	// add by lin
+	ProviderEventDealPublishedOfSxx
+	// end
 )
 
 // ProviderEvents maps provider event codes to string names
@@ -339,6 +343,9 @@ var ProviderEvents = map[ProviderEvent]string{
 	ProviderEventDealPrecommitFailed:         "ProviderEventDealPrecommitFailed",
 	ProviderEventDealPrecommitted:            "ProviderEventDealPrecommitted",
 	ProviderEventAwaitTransferRestartTimeout: "ProviderEventAwaitTransferRestartTimeout",
+	// add by lin
+	ProviderEventDealPublishedOfSxx: "ProviderEventDealPublishedOfSxx",
+	// end
 }
 
 func (e ProviderEvent) String() string {
diff --git a/extern/sxx-go-fil-markets@v1.28.3/storagemarket/impl/clientstates/client_states.go b/extern/sxx-go-fil-markets@v1.28.3/storagemarket/impl/clientstates/client_states.go
index 22b66c058..15508ed2a 100644
--- a/extern/sxx-go-fil-markets@v1.28.3/storagemarket/impl/clientstates/client_states.go
+++ b/extern/sxx-go-fil-markets@v1.28.3/storagemarket/impl/clientstates/client_states.go
@@ -349,6 +349,9 @@ func releaseReservedFunds(ctx fsm.Context, environment ClientDealEnvironment, de
 
 func isAccepted(status storagemarket.StorageDealStatus) bool {
 	return status == storagemarket.StorageDealStaged ||
+		// add by lin
+		status == storagemarket.StorageDealStagedOfSxx ||
+		// end
 		status == storagemarket.StorageDealAwaitingPreCommit ||
 		status == storagemarket.StorageDealSealing ||
 		status == storagemarket.StorageDealActive ||
diff --git a/extern/sxx-go-fil-markets@v1.28.3/storagemarket/impl/provider.go b/extern/sxx-go-fil-markets@v1.28.3/storagemarket/impl/provider.go
index b2a8a91af..f42ca70d8 100644
--- a/extern/sxx-go-fil-markets@v1.28.3/storagemarket/impl/provider.go
+++ b/extern/sxx-go-fil-markets@v1.28.3/storagemarket/impl/provider.go
@@ -350,6 +350,74 @@ func (p *Provider) Stop() error {
 	return p.net.StopHandlingRequests()
 }
 
+// add by lin
+func (p *Provider) ImportDataForDealOfSxx(ctx context.Context, propCid cid.Cid, fname string) error {
+	// TODO: be able to check if we have enough disk space
+	var d storagemarket.MinerDeal
+	if err := p.deals.Get(propCid).Get(&d); err != nil {
+		return xerrors.Errorf("failed getting deal %s: %w", propCid, err)
+	}
+
+	tempfi, err := os.Open(fname)
+	if err != nil {
+		return xerrors.Errorf("failed to open given file: %w", err)
+	}
+
+	defer tempfi.Close()
+	cleanup := func() {
+		_ = tempfi.Close()
+	}
+
+	filestat, _ := tempfi.Stat()
+	carSize := uint64(filestat.Size())
+
+	_, err = tempfi.Seek(0, io.SeekStart)
+	if err != nil {
+		cleanup()
+		return xerrors.Errorf("failed to seek through temp imported file: %w", err)
+	}
+
+	if carSizePadded := padreader.PaddedSize(carSize).Padded(); carSizePadded < d.Proposal.PieceSize {
+		// need to pad up!
+		proofType, err := p.spn.GetProofType(ctx, p.actor, nil)
+		if err != nil {
+			cleanup()
+			return xerrors.Errorf("failed to determine proof type: %w", err)
+		}
+		log.Debugw("fetched proof type", "propCid", propCid)
+
+		pieceCid, err := generatePieceCommitment(proofType, tempfi, carSize)
+		if err != nil {
+			cleanup()
+			return xerrors.Errorf("failed to generate commP: %w", err)
+		}
+		log.Debugw("generated pieceCid for imported file", "propCid", propCid)
+
+		rawPaddedCommp, err := commp.PadCommP(
+			// we know how long a pieceCid "hash" is, just blindly extract the trailing 32 bytes
+			pieceCid.Hash()[len(pieceCid.Hash())-32:],
+			uint64(carSizePadded),
+			uint64(d.Proposal.PieceSize),
+		)
+		if err != nil {
+			cleanup()
+			return err
+		}
+		pieceCid, _ = commcid.DataCommitmentV1ToCID(rawPaddedCommp)
+
+		if !pieceCid.Equals(d.Proposal.PieceCID) {
+			cleanup()
+			return xerrors.Errorf("given data does not match expected commP (got: %s, expected %s)", pieceCid, d.Proposal.PieceCID)
+		}
+	}
+
+	log.Debugw("will fire ProviderEventVerifiedData for file", "propCid", propCid)
+
+	return p.deals.Send(propCid, storagemarket.ProviderEventVerifiedData, filestore.Path(fname), filestore.Path(""))
+}
+
+// end
+
 // ImportDataForDeal manually imports data for an offline storage deal
 // It will verify that the data in the passed io.Reader matches the expected piece
 // cid for the given deal or it will error
diff --git a/extern/sxx-go-fil-markets@v1.28.3/storagemarket/impl/providerstates/provider_fsm.go b/extern/sxx-go-fil-markets@v1.28.3/storagemarket/impl/providerstates/provider_fsm.go
index c5a727020..e186e2f81 100644
--- a/extern/sxx-go-fil-markets@v1.28.3/storagemarket/impl/providerstates/provider_fsm.go
+++ b/extern/sxx-go-fil-markets@v1.28.3/storagemarket/impl/providerstates/provider_fsm.go
@@ -134,36 +134,47 @@ var ProviderEvents = fsm.Events{
 			deal.PublishCid = &finalCid
 			return nil
 		}),
+	// add by lin
+	fsm.Event(storagemarket.ProviderEventDealPublishedOfSxx).
+		From(storagemarket.StorageDealPublishing).To(storagemarket.StorageDealStagedOfSxx).
+		Action(func(deal *storagemarket.MinerDeal, dealID abi.DealID, finalCid cid.Cid) error {
+			deal.DealID = dealID
+			deal.PublishCid = &finalCid
+			return nil
+		}),
+	// end
+	// change by lin
 	fsm.Event(storagemarket.ProviderEventFileStoreErrored).
-		FromMany(storagemarket.StorageDealStaged, storagemarket.StorageDealAwaitingPreCommit, storagemarket.StorageDealSealing, storagemarket.StorageDealActive).To(storagemarket.StorageDealFailing).
+		FromMany(storagemarket.StorageDealStaged, storagemarket.StorageDealStagedOfSxx, storagemarket.StorageDealAwaitingPreCommit, storagemarket.StorageDealSealing, storagemarket.StorageDealActive).To(storagemarket.StorageDealFailing).
 		Action(func(deal *storagemarket.MinerDeal, err error) error {
 			deal.Message = xerrors.Errorf("accessing file store: %w", err).Error()
 			return nil
 		}),
 
 	fsm.Event(storagemarket.ProviderEventMultistoreErrored).
-		FromMany(storagemarket.StorageDealStaged).To(storagemarket.StorageDealFailing).
+		FromMany(storagemarket.StorageDealStaged, storagemarket.StorageDealStagedOfSxx).To(storagemarket.StorageDealFailing).
 		Action(func(deal *storagemarket.MinerDeal, err error) error {
 			deal.Message = xerrors.Errorf("operating on multistore: %w", err).Error()
 			return nil
 		}),
-	fsm.Event(storagemarket.ProviderEventDealHandoffFailed).From(storagemarket.StorageDealStaged).To(storagemarket.StorageDealFailing).
+	fsm.Event(storagemarket.ProviderEventDealHandoffFailed).FromMany(storagemarket.StorageDealStaged, storagemarket.StorageDealStagedOfSxx).To(storagemarket.StorageDealFailing).
 		Action(func(deal *storagemarket.MinerDeal, err error) error {
 			deal.Message = xerrors.Errorf("handing off deal to node: %w", err).Error()
 			return nil
 		}),
 	fsm.Event(storagemarket.ProviderEventPieceStoreErrored).
-		From(storagemarket.StorageDealStaged).ToJustRecord().
+		FromMany(storagemarket.StorageDealStaged, storagemarket.StorageDealStagedOfSxx).ToJustRecord().
 		Action(func(deal *storagemarket.MinerDeal, err error) error {
 			deal.Message = xerrors.Errorf("recording piece for retrieval: %w", err).Error()
 			return nil
 		}),
 	fsm.Event(storagemarket.ProviderEventDealHandedOff).
-		From(storagemarket.StorageDealStaged).To(storagemarket.StorageDealAwaitingPreCommit).
+		FromMany(storagemarket.StorageDealStaged, storagemarket.StorageDealStagedOfSxx).To(storagemarket.StorageDealAwaitingPreCommit).
 		Action(func(deal *storagemarket.MinerDeal) error {
 			deal.AvailableForRetrieval = true
 			return nil
 		}),
+	// end
 	fsm.Event(storagemarket.ProviderEventDealPrecommitFailed).
 		From(storagemarket.StorageDealAwaitingPreCommit).To(storagemarket.StorageDealFailing).
 		Action(func(deal *storagemarket.MinerDeal, err error) error {
@@ -258,12 +269,15 @@ var ProviderStateEntryFuncs = fsm.StateEntryFuncs{
 	storagemarket.StorageDealPublish:                      PublishDeal,
 	storagemarket.StorageDealPublishing:                   WaitForPublish,
 	storagemarket.StorageDealStaged:                       HandoffDeal,
-	storagemarket.StorageDealAwaitingPreCommit:            VerifyDealPreCommitted,
-	storagemarket.StorageDealSealing:                      VerifyDealActivated,
-	storagemarket.StorageDealRejecting:                    RejectDeal,
-	storagemarket.StorageDealFinalizing:                   CleanupDeal,
-	storagemarket.StorageDealActive:                       WaitForDealCompletion,
-	storagemarket.StorageDealFailing:                      FailDeal,
+	// add by lin
+	storagemarket.StorageDealStagedOfSxx: HandoffDealOfSxx,
+	// end
+	storagemarket.StorageDealAwaitingPreCommit: VerifyDealPreCommitted,
+	storagemarket.StorageDealSealing:           VerifyDealActivated,
+	storagemarket.StorageDealRejecting:         RejectDeal,
+	storagemarket.StorageDealFinalizing:        CleanupDeal,
+	storagemarket.StorageDealActive:            WaitForDealCompletion,
+	storagemarket.StorageDealFailing:           FailDeal,
 }
 
 // ProviderFinalityStates are the states that terminate deal processing for a deal.
diff --git a/extern/sxx-go-fil-markets@v1.28.3/storagemarket/impl/providerstates/provider_states.go b/extern/sxx-go-fil-markets@v1.28.3/storagemarket/impl/providerstates/provider_states.go
index 4a07c3088..543946c31 100644
--- a/extern/sxx-go-fil-markets@v1.28.3/storagemarket/impl/providerstates/provider_states.go
+++ b/extern/sxx-go-fil-markets@v1.28.3/storagemarket/impl/providerstates/provider_states.go
@@ -4,6 +4,7 @@ import (
 	"context"
 	"fmt"
 	"io"
+	"os"
 	"strings"
 	"time"
 
@@ -30,6 +31,17 @@ import (
 
 var log = logging.Logger("providerstates")
 
+// add by lin
+type ReadSeekStarter struct {
+	io.Reader
+}
+
+func (r *ReadSeekStarter) SeekStart() error {
+	return nil
+}
+
+// end
+
 // TODO: These are copied from spec-actors master, use spec-actors exports when we update
 const DealMaxLabelSize = 256
 
@@ -326,9 +338,78 @@ func WaitForPublish(ctx fsm.Context, environment ProviderDealEnvironment, deal s
 	// for deal publishing
 	releaseReservedFunds(ctx, environment, deal)
 
+	// add by lin
+	if os.Getenv("LOTUS_OF_SXX") == "1" && strings.HasPrefix(string(deal.PiecePath), "/") {
+		return ctx.Trigger(storagemarket.ProviderEventDealPublishedOfSxx, res.DealID, res.FinalCid)
+	}
+	log.Errorw("zlin: unuse SXX publish")
+	// end
+
 	return ctx.Trigger(storagemarket.ProviderEventDealPublished, res.DealID, res.FinalCid)
 }
 
+// add by lin
+func HandoffDealOfSxx(ctx fsm.Context, environment ProviderDealEnvironment, deal storagemarket.MinerDeal) error {
+	carFilePath := string(deal.PiecePath)
+	if deal.PiecePath == "" {
+		err := xerrors.Errorf("our path of deal car is nil")
+		return ctx.Trigger(storagemarket.ProviderEventDealHandoffFailed, err)
+	}
+	// Data for offline deals is stored on disk, so if PiecePath is set,
+	// create a Reader from the file path
+	var reader shared.ReadSeekStarter
+	reader = &ReadSeekStarter{io.LimitReader(nil, 0)}
+
+	packingInfo, err := environment.Node().OnDealCompleteOfSxx(
+		ctx.Context(),
+		storagemarket.MinerDeal{
+			Client:             deal.Client,
+			ClientDealProposal: deal.ClientDealProposal,
+			ProposalCid:        deal.ProposalCid,
+			State:              deal.State,
+			Ref:                deal.Ref,
+			PublishCid:         deal.PublishCid,
+			DealID:             deal.DealID,
+			FastRetrieval:      deal.FastRetrieval,
+			RemoteFilepath:     carFilePath,
+		},
+		deal.Proposal.PieceSize.Unpadded(),
+		reader,
+	)
+
+	if err != nil {
+		err = xerrors.Errorf("packing piece at path %s: %w", deal.PiecePath, err)
+		return ctx.Trigger(storagemarket.ProviderEventDealHandoffFailed, err)
+	}
+
+	if err := recordPiece(environment, deal, packingInfo.SectorNumber, packingInfo.Offset, packingInfo.Size); err != nil {
+		err = xerrors.Errorf("failed to register deal data for piece %s for retrieval: %w", deal.Ref.PieceCid, err)
+		log.Error(err.Error())
+		_ = ctx.Trigger(storagemarket.ProviderEventPieceStoreErrored, err)
+	}
+
+	// Register the deal data as a "shard" with the DAG store. Later it can be
+	// fetched from the DAG store during retrieval.
+	if err := environment.RegisterShard(ctx.Context(), deal.Proposal.PieceCID, carFilePath, true); err != nil {
+		err = xerrors.Errorf("failed to activate shard: %w", err)
+		log.Error(err)
+	}
+
+	// announce the deal to the network indexer
+	annCid, err := environment.AnnounceIndex(ctx.Context(), deal)
+	if err != nil {
+		log.Errorw("failed to announce index via reference provider", "proposalCid", deal.ProposalCid, "err", err)
+	} else {
+		log.Infow("deal announcement sent to index provider", "advertisementCid", annCid, "shard-key", deal.Proposal.PieceCID,
+			"proposalCid", deal.ProposalCid)
+	}
+
+	log.Infow("successfully handed off deal to sealing subsystem", "pieceCid", deal.Proposal.PieceCID, "proposalCid", deal.ProposalCid)
+	return ctx.Trigger(storagemarket.ProviderEventDealHandedOff)
+}
+
+// end
+
 // HandoffDeal hands off a published deal for sealing and commitment in a sector
 func HandoffDeal(ctx fsm.Context, environment ProviderDealEnvironment, deal storagemarket.MinerDeal) error {
 	var packingInfo *storagemarket.PackingResult
diff --git a/extern/sxx-go-fil-markets@v1.28.3/storagemarket/nodes.go b/extern/sxx-go-fil-markets@v1.28.3/storagemarket/nodes.go
index a2128afdf..7f8332613 100644
--- a/extern/sxx-go-fil-markets@v1.28.3/storagemarket/nodes.go
+++ b/extern/sxx-go-fil-markets@v1.28.3/storagemarket/nodes.go
@@ -96,6 +96,10 @@ type StorageProviderNode interface {
 	// OnDealComplete is called when a deal is complete and on chain, and data has been transferred and is ready to be added to a sector
 	OnDealComplete(ctx context.Context, deal MinerDeal, pieceSize abi.UnpaddedPieceSize, pieceReader shared.ReadSeekStarter) (*PackingResult, error)
 
+	// add by lin
+	OnDealCompleteOfSxx(ctx context.Context, deal MinerDeal, pieceSize abi.UnpaddedPieceSize, pieceReader shared.ReadSeekStarter) (*PackingResult, error)
+	// end
+
 	// GetMinerWorkerAddress returns the worker address associated with a miner
 	GetMinerWorkerAddress(ctx context.Context, addr address.Address, tok shared.TipSetToken) (address.Address, error)
 
diff --git a/extern/sxx-go-fil-markets@v1.28.3/storagemarket/provider.go b/extern/sxx-go-fil-markets@v1.28.3/storagemarket/provider.go
index b3a2213bf..088a72edd 100644
--- a/extern/sxx-go-fil-markets@v1.28.3/storagemarket/provider.go
+++ b/extern/sxx-go-fil-markets@v1.28.3/storagemarket/provider.go
@@ -59,6 +59,10 @@ type StorageProvider interface {
 	// ImportDataForDeal manually imports data for an offline storage deal
 	ImportDataForDeal(ctx context.Context, propCid cid.Cid, data io.Reader) error
 
+	// add by lin
+	ImportDataForDealOfSxx(ctx context.Context, propCid cid.Cid, path string) error
+	// end
+
 	// SubscribeToEvents listens for events that happen related to storage deals on a provider
 	SubscribeToEvents(subscriber ProviderSubscriber) shared.Unsubscribe
 
diff --git a/extern/sxx-go-fil-markets@v1.28.3/storagemarket/types.go b/extern/sxx-go-fil-markets@v1.28.3/storagemarket/types.go
index da087dd54..109475bfe 100644
--- a/extern/sxx-go-fil-markets@v1.28.3/storagemarket/types.go
+++ b/extern/sxx-go-fil-markets@v1.28.3/storagemarket/types.go
@@ -115,6 +115,10 @@ type MinerDeal struct {
 	SectorNumber      abi.SectorNumber
 
 	InboundCAR string
+
+	// add by lin
+	RemoteFilepath string
+	// end
 }
 
 // NewDealStages creates a new DealStages object ready to be used.
diff --git a/go.mod b/go.mod
index 44b6e5e7a..409bc8acd 100644
--- a/go.mod
+++ b/go.mod
@@ -175,6 +175,7 @@ require (
 )
 
 require (
+	filbase/filbase_redis v0.0.0-00010101000000-000000000000 // indirect
 	github.com/GeertJohan/go.incremental v1.0.0 // indirect
 	github.com/Jorropo/jsync v1.0.1 // indirect
 	github.com/PuerkitoBio/purell v1.1.1 // indirect
@@ -200,6 +201,7 @@ require (
 	github.com/decred/dcrd/dcrec/secp256k1/v4 v4.2.0 // indirect
 	github.com/dgraph-io/ristretto v0.1.1 // indirect
 	github.com/dgryski/go-farm v0.0.0-20200201041132-a6ae2369ad13 // indirect
+	github.com/dgryski/go-rendezvous v0.0.0-20200823014737-9f7001d12a5f // indirect
 	github.com/drand/kyber-bls12381 v0.3.1 // indirect
 	github.com/elastic/go-windows v1.0.0 // indirect
 	github.com/etclabscore/go-jsonschema-walk v0.0.6 // indirect
@@ -287,6 +289,7 @@ require (
 	github.com/mikioh/tcpinfo v0.0.0-20190314235526-30a79bb1804b // indirect
 	github.com/mikioh/tcpopt v0.0.0-20190314235656-172688c1accc // indirect
 	github.com/minio/sha256-simd v1.0.1 // indirect
+	github.com/moran666666/sector-counter v0.0.0-00010101000000-000000000000 // indirect
 	github.com/mr-tron/base58 v1.2.0 // indirect
 	github.com/multiformats/go-base36 v0.2.0 // indirect
 	github.com/multiformats/go-multiaddr-fmt v0.1.0 // indirect
@@ -305,6 +308,7 @@ require (
 	github.com/quic-go/qpack v0.4.0 // indirect
 	github.com/quic-go/quic-go v0.42.0 // indirect
 	github.com/quic-go/webtransport-go v0.6.0 // indirect
+	github.com/redis/go-redis/v9 v9.0.3 // indirect
 	github.com/rivo/uniseg v0.1.0 // indirect
 	github.com/rs/cors v1.7.0 // indirect
 	github.com/russross/blackfriday/v2 v2.1.0 // indirect
@@ -341,8 +345,6 @@ require (
 	gopkg.in/yaml.v3 v3.0.1 // indirect
 	howett.net/plist v0.0.0-20181124034731-591f970eefbb // indirect
 	lukechampine.com/blake3 v1.2.1 // indirect
-	github.com/moran666666/sector-counter v0.0.0-00010101000000-000000000000 // indirect
-    filbase/filbase_redis v0.0.0-00010101000000-000000000000 // indirect
 )
 
 replace github.com/filecoin-project/filecoin-ffi => ./extern/filecoin-ffi
@@ -355,4 +357,4 @@ replace github.com/moran666666/sector-counter => ./extern/sxx-sector-counter
 
 replace github.com/filecoin-project/go-fil-markets => ./extern/sxx-go-fil-markets@v1.28.3
 
-replace filbase/filbase_redis => ./extern/filbase/filbase_redis
\ No newline at end of file
+replace filbase/filbase_redis => ./extern/filbase/filbase_redis
diff --git a/go.sum b/go.sum
index b5fb5867d..53be970b6 100644
--- a/go.sum
+++ b/go.sum
@@ -243,6 +243,8 @@ github.com/dgryski/go-farm v0.0.0-20190104051053-3adb47b1fb0f/go.mod h1:SqUrOPUn
 github.com/dgryski/go-farm v0.0.0-20190423205320-6a90982ecee2/go.mod h1:SqUrOPUnsFjfmXRMNPybcSiG0BgUW2AuFH8PAnS2iTw=
 github.com/dgryski/go-farm v0.0.0-20200201041132-a6ae2369ad13 h1:fAjc9m62+UWV/WAFKLNi6ZS0675eEUC9y3AlwSbQu1Y=
 github.com/dgryski/go-farm v0.0.0-20200201041132-a6ae2369ad13/go.mod h1:SqUrOPUnsFjfmXRMNPybcSiG0BgUW2AuFH8PAnS2iTw=
+github.com/dgryski/go-rendezvous v0.0.0-20200823014737-9f7001d12a5f h1:lO4WD4F/rVNCu3HqELle0jiPLLBs70cWOduZpkS1E78=
+github.com/dgryski/go-rendezvous v0.0.0-20200823014737-9f7001d12a5f/go.mod h1:cuUVRXasLTGF7a8hSLbxyZXjz+1KgoB3wDUb6vlszIc=
 github.com/docker/go-units v0.4.0/go.mod h1:fgPhTUdO+D/Jk86RDLlptpiXQzgHJF7gydDDbaIK4Dk=
 github.com/docker/go-units v0.5.0 h1:69rxXcBk27SvSaaxTtLh/8llcHD8vYHT7WSdRZ/jvr4=
 github.com/docker/go-units v0.5.0/go.mod h1:fgPhTUdO+D/Jk86RDLlptpiXQzgHJF7gydDDbaIK4Dk=
@@ -1512,6 +1514,8 @@ github.com/raulk/clock v1.1.0/go.mod h1:3MpVxdZ/ODBQDxbN+kzshf5OSZwPjtMDx6BBXBmO
 github.com/raulk/go-watchdog v1.3.0 h1:oUmdlHxdkXRJlwfG0O9omj8ukerm8MEQavSiDTEtBsk=
 github.com/raulk/go-watchdog v1.3.0/go.mod h1:fIvOnLbF0b0ZwkB9YU4mOW9Did//4vPZtDqv66NfsMU=
 github.com/rcrowley/go-metrics v0.0.0-20181016184325-3113b8401b8a/go.mod h1:bCqnVzQkZxMG4s8nGwiZ5l3QUCyqpo9Y+/ZMZ9VjZe4=
+github.com/redis/go-redis/v9 v9.0.3 h1:+7mmR26M0IvyLxGZUHxu4GiBkJkVDid0Un+j4ScYu4k=
+github.com/redis/go-redis/v9 v9.0.3/go.mod h1:WqMKv5vnQbRuZstUwxQI195wHy+t4PuXDOjzMvcuQHk=
 github.com/rivo/uniseg v0.1.0 h1:+2KBaVoUmb9XzDsrx/Ct0W/EYOSFf/nWTauy++DprtY=
 github.com/rivo/uniseg v0.1.0/go.mod h1:J6wj4VEh+S6ZtnVlnTBMWIodfgj8LQOQFoIToxlJtxc=
 github.com/rogpeppe/fastuuid v0.0.0-20150106093220-6724a57986af/go.mod h1:XWv6SoW27p1b0cqNHllgS5HIMJraePCO15w5zCzIWYg=
diff --git a/markets/storageadapter/provider.go b/markets/storageadapter/provider.go
index 11742c879..555aa16f3 100644
--- a/markets/storageadapter/provider.go
+++ b/markets/storageadapter/provider.go
@@ -88,6 +88,70 @@ func (n *ProviderNodeAdapter) PublishDeals(ctx context.Context, deal storagemark
 	return n.dealPublisher.Publish(ctx, deal.ClientDealProposal)
 }
 
+// add by lin
+func (n *ProviderNodeAdapter) OnDealCompleteOfSxx(ctx context.Context, deal storagemarket.MinerDeal, pieceSize abi.UnpaddedPieceSize, pieceData shared.ReadSeekStarter) (*storagemarket.PackingResult, error) {
+	if deal.PublishCid == nil {
+		return nil, xerrors.Errorf("deal.PublishCid can't be nil")
+	}
+
+	sdInfo := api.PieceDealInfo{
+		DealID:       deal.DealID,
+		DealProposal: &deal.Proposal,
+		PublishCid:   deal.PublishCid,
+		DealSchedule: api.DealSchedule{
+			StartEpoch: deal.ClientDealProposal.Proposal.StartEpoch,
+			EndEpoch:   deal.ClientDealProposal.Proposal.EndEpoch,
+		},
+		KeepUnsealed:   deal.FastRetrieval,
+		RemoteFilepath: deal.RemoteFilepath,
+	}
+
+	// Attempt to add the piece to the sector
+	p, offset, err := n.secb.AddPiece(ctx, pieceSize, pieceData, sdInfo)
+	curTime := build.Clock.Now()
+	for build.Clock.Since(curTime) < addPieceRetryTimeout {
+		// Check if there was an error because of too many sectors being sealed
+		if !xerrors.Is(err, pipeline.ErrTooManySectorsSealing) {
+			if err != nil {
+				log.Errorf("failed to addPiece for deal %d, err: %v", deal.DealID, err)
+			}
+
+			// There was either a fatal error or no error. In either case
+			// don't retry AddPiece
+			break
+		}
+
+		// The piece could not be added to the sector because there are too
+		// many sectors being sealed, back-off for a while before trying again
+		select {
+		case <-build.Clock.After(addPieceRetryWait):
+			// Reset the reader to the start
+			err = pieceData.SeekStart()
+			if err != nil {
+				return nil, xerrors.Errorf("failed to reset piece reader to start before retrying AddPiece for deal %d: %w", deal.DealID, err)
+			}
+
+			// Attempt to add the piece again
+			p, offset, err = n.secb.AddPiece(ctx, pieceSize, pieceData, sdInfo)
+		case <-ctx.Done():
+			return nil, xerrors.New("context expired while waiting to retry AddPiece")
+		}
+	}
+
+	if err != nil {
+		return nil, xerrors.Errorf("AddPiece failed: %s", err)
+	}
+	log.Warnf("New Deal: deal %d", deal.DealID)
+
+	return &storagemarket.PackingResult{
+		SectorNumber: p,
+		Offset:       offset,
+		Size:         pieceSize.Padded(),
+	}, nil
+}
+
+// end
+
 func (n *ProviderNodeAdapter) OnDealComplete(ctx context.Context, deal storagemarket.MinerDeal, pieceSize abi.UnpaddedPieceSize, pieceData shared.ReadSeekStarter) (*storagemarket.PackingResult, error) {
 	if deal.PublishCid == nil {
 		return nil, xerrors.Errorf("deal.PublishCid can't be nil")
diff --git a/miner/miner.go b/miner/miner.go
index d11e9d4aa..15966c9d4 100644
--- a/miner/miner.go
+++ b/miner/miner.go
@@ -146,7 +146,15 @@ func (m *Miner) Start(_ context.Context) error {
 		return fmt.Errorf("miner already started")
 	}
 	m.stop = make(chan struct{})
-	go m.mine(context.TODO())
+	//go m.mine(context.TODO())
+
+	// change by sxx
+	if _, ok := os.LookupEnv("LOTUS_WNPOST"); ok {
+		go m.mine(context.TODO())
+	} else {
+		log.Warnf("This miner will be disable minning block function.")
+	}
+	// end
 	return nil
 }
 
diff --git a/node/impl/client/client.go b/node/impl/client/client.go
index c7bb252a1..597b1a93a 100644
--- a/node/impl/client/client.go
+++ b/node/impl/client/client.go
@@ -271,11 +271,21 @@ func (a *API) dealStarter(ctx context.Context, params *api.StartDealParams, isSt
 		Proposal:        *dealProposal,
 		ClientSignature: *dealProposalSig,
 	}
+
+	// change by pan
+	peerid := *mi.PeerId
+	if params.Peerid != nil {
+		peerid = *params.Peerid
+		log.Infof("miner peerid %s/*", peerid)
+	}
+
 	dStream, err := network.NewFromLibp2pHost(a.Host,
 		// params duplicated from .../node/modules/client.go
 		// https://github.com/filecoin-project/lotus/pull/5961#discussion_r629768011
 		network.RetryParameters(time.Second, 5*time.Minute, 15, 5),
-	).NewDealStream(ctx, *mi.PeerId)
+	// ).NewDealStream(ctx, *mi.PeerId)
+	).NewDealStream(ctx, peerid)
+	// end
 	if err != nil {
 		return nil, xerrors.Errorf("opening dealstream to %s/%s failed: %w", params.Miner, *mi.PeerId, err)
 	}
@@ -314,6 +324,112 @@ func (a *API) dealStarter(ctx context.Context, params *api.StartDealParams, isSt
 	return &resp.Response.Proposal, nil
 }
 
+func (a *API) ClientStatelessDealSxx(ctx context.Context, params *api.StartDealParams) (*network.Proposal, error) {
+	if params.Data.TransferType != storagemarket.TTManual {
+		return nil, xerrors.Errorf("invalid transfer type %s for stateless storage deal", params.Data.TransferType)
+	}
+	if !params.EpochPrice.IsZero() {
+		return nil, xerrors.New("stateless storage deals can only be initiated with storage price of 0")
+	}
+
+	walletKey, err := a.StateAccountKey(ctx, params.Wallet, types.EmptyTSK)
+	if err != nil {
+		return nil, xerrors.Errorf("failed resolving params.Wallet addr (%s): %w", params.Wallet, err)
+	}
+
+	exist, err := a.WalletHas(ctx, walletKey)
+	if err != nil {
+		return nil, xerrors.Errorf("failed getting addr from wallet (%s): %w", params.Wallet, err)
+	}
+	if !exist {
+		return nil, xerrors.Errorf("provided address doesn't exist in wallet")
+	}
+
+	mi, err := a.StateMinerInfo(ctx, params.Miner, types.EmptyTSK)
+	if err != nil {
+		return nil, xerrors.Errorf("failed getting peer ID: %w", err)
+	}
+
+	md, err := a.StateMinerProvingDeadline(ctx, params.Miner, types.EmptyTSK)
+	if err != nil {
+		return nil, xerrors.Errorf("failed getting miner's deadline info: %w", err)
+	}
+
+	if uint64(params.Data.PieceSize.Padded()) > uint64(mi.SectorSize) {
+		return nil, xerrors.New("data doesn't fit in a sector")
+	}
+
+	dealStart := params.DealStartEpoch
+	if dealStart <= 0 { // unset, or explicitly 'epoch undefined'
+		ts, err := a.ChainHead(ctx)
+		if err != nil {
+			return nil, xerrors.Errorf("failed getting chain height: %w", err)
+		}
+
+		blocksPerHour := 60 * 60 / build.BlockDelaySecs
+		dealStart = ts.Height() + abi.ChainEpoch(dealStartBufferHours*blocksPerHour) // TODO: Get this from storage ask
+	}
+
+	//
+	// stateless flow from here to the end
+	//
+
+	label, err := markettypes.NewLabelFromString(params.Data.Root.Encode(multibase.MustNewEncoder('u')))
+	if err != nil {
+		return nil, xerrors.Errorf("failed to encode label: %w", err)
+	}
+
+	dealProposal := &markettypes.DealProposal{
+		PieceCID:             *params.Data.PieceCid,
+		PieceSize:            params.Data.PieceSize.Padded(),
+		Client:               walletKey,
+		Provider:             params.Miner,
+		Label:                label,
+		StartEpoch:           dealStart,
+		EndEpoch:             calcDealExpiration(params.MinBlocksDuration, md, dealStart),
+		StoragePricePerEpoch: big.Zero(),
+		ProviderCollateral:   params.ProviderCollateral,
+		ClientCollateral:     big.Zero(),
+		VerifiedDeal:         params.VerifiedDeal,
+	}
+
+	if dealProposal.ProviderCollateral.IsZero() {
+		networkCollateral, err := a.StateDealProviderCollateralBounds(ctx, params.Data.PieceSize.Padded(), params.VerifiedDeal, types.EmptyTSK)
+		if err != nil {
+			return nil, xerrors.Errorf("failed to determine minimum provider collateral: %w", err)
+		}
+		dealProposal.ProviderCollateral = networkCollateral.Min
+	}
+
+	dealProposalSerialized, err := cborutil.Dump(dealProposal)
+	if err != nil {
+		return nil, xerrors.Errorf("failed to serialize deal proposal: %w", err)
+	}
+
+	dealProposalSig, err := a.WalletSign(ctx, walletKey, dealProposalSerialized)
+	if err != nil {
+		return nil, xerrors.Errorf("failed to sign proposal : %w", err)
+	}
+
+	dealProposalSigned := &markettypes.ClientDealProposal{
+		Proposal:        *dealProposal,
+		ClientSignature: *dealProposalSig,
+	}
+
+	proposal := network.Proposal{
+		FastRetrieval: true,
+		DealProposal:  dealProposalSigned,
+		Piece: &storagemarket.DataRef{
+			TransferType: storagemarket.TTManual,
+			Root:         params.Data.Root,
+			PieceCid:     params.Data.PieceCid,
+			PieceSize:    params.Data.PieceSize,
+		},
+	}
+
+	return &proposal, nil
+}
+
 func (a *API) ClientListDeals(ctx context.Context) ([]api.DealInfo, error) {
 	deals, err := a.SMDealClient.ListLocalDeals(ctx)
 	if err != nil {
diff --git a/node/impl/storminer.go b/node/impl/storminer.go
index 90248a355..21ade0ffa 100644
--- a/node/impl/storminer.go
+++ b/node/impl/storminer.go
@@ -414,6 +414,10 @@ func (sm *StorageMinerAPI) SectorsUpdate(ctx context.Context, id abi.SectorNumbe
 	return sm.Miner.ForceSectorState(ctx, id, sealing.SectorState(state))
 }
 
+func (sm *StorageMinerAPI) SectorsUpdateOfSxx(ctx context.Context, id abi.SectorNumber, state api.SectorState, worker string) error {
+	return sm.Miner.ForceSectorStateOfSxx(ctx, id, sealing.SectorState(state), worker)
+}
+
 func (sm *StorageMinerAPI) SectorRemove(ctx context.Context, id abi.SectorNumber) error {
 	return sm.Miner.RemoveSector(ctx, id)
 }
@@ -1242,6 +1246,14 @@ func (sm *StorageMinerAPI) DealsSetExpectedSealDurationFunc(ctx context.Context,
 	return sm.SetExpectedSealDurationFunc(d)
 }
 
+// add by lin
+func (sm *StorageMinerAPI) DealsImportDataOfSxx(ctx context.Context, deal cid.Cid, fname string) error {
+
+	return sm.StorageProvider.ImportDataForDealOfSxx(ctx, deal, fname)
+}
+
+// end
+
 func (sm *StorageMinerAPI) DealsImportData(ctx context.Context, deal cid.Cid, fname string) error {
 	fi, err := os.Open(fname)
 	if err != nil {
@@ -1339,6 +1351,35 @@ func (sm *StorageMinerAPI) CheckProvable(ctx context.Context, pp abi.RegisteredP
 	return out, nil
 }
 
+func (sm *StorageMinerAPI) CheckProve(ctx context.Context, pp abi.RegisteredPoStProof, sectors []storiface.SectorRef, update []bool, expensive bool) (map[abi.SectorNumber]string, error) {
+	var rg storiface.RGetter
+	if expensive {
+		rg = func(ctx context.Context, id abi.SectorID) (cid.Cid, bool, error) {
+			si, err := sm.Miner.SectorsStatus(ctx, id.Number, false)
+			if err != nil {
+				return cid.Undef, false, err
+			}
+			if si.CommR == nil {
+				return cid.Undef, false, xerrors.Errorf("commr is nil")
+			}
+
+			return *si.CommR, si.ReplicaUpdateMessage != nil, nil
+		}
+	}
+
+	bad, err := sm.StorageMgr.CheckProve(ctx, pp, sectors, update, rg)
+	if err != nil {
+		return nil, err
+	}
+
+	var out = make(map[abi.SectorNumber]string)
+	for sid, err := range bad {
+		out[sid.Number] = err
+	}
+
+	return out, nil
+}
+
 func (sm *StorageMinerAPI) ActorAddressConfig(ctx context.Context) (api.AddressConfig, error) {
 	return sm.AddrSel.AddressConfig, nil
 }
diff --git a/node/modules/storageminer.go b/node/modules/storageminer.go
index e27a497bb..6c54a63bd 100644
--- a/node/modules/storageminer.go
+++ b/node/modules/storageminer.go
@@ -323,7 +323,14 @@ func WindowPostScheduler(fc config.MinerFeeConfig, pc config.ProvingConfig) func
 
 		lc.Append(fx.Hook{
 			OnStart: func(context.Context) error {
-				go fps.Run(ctx)
+				// go fps.Run(ctx)
+				// change by sxx
+				if _, ok := os.LookupEnv("LOTUS_WDPOST"); ok {
+					go fps.Run(ctx)
+				} else {
+					log.Warnf("This miner will be disable windowPoSt.")
+				}
+				// end
 				return nil
 			},
 		})
diff --git a/provider/lpwindow/faults_simple.go b/provider/lpwindow/faults_simple.go
index d43e8ee19..9d00f573c 100644
--- a/provider/lpwindow/faults_simple.go
+++ b/provider/lpwindow/faults_simple.go
@@ -150,3 +150,8 @@ func (m *SimpleFaultTracker) CheckProvable(ctx context.Context, pp abi.Registere
 
 	return bad, nil
 }
+
+func (m *SimpleFaultTracker) CheckProve(ctx context.Context, pp abi.RegisteredPoStProof, sectors []storiface.SectorRef, update []bool, rg storiface.RGetter) (map[abi.SectorID]string, error) {
+
+	return nil, nil
+}
diff --git a/storage/pipeline/fsm.go b/storage/pipeline/fsm.go
index ced6867d1..e245a82b2 100644
--- a/storage/pipeline/fsm.go
+++ b/storage/pipeline/fsm.go
@@ -7,6 +7,7 @@ import (
 	"context"
 	"encoding/json"
 	"errors"
+	"filbase/filbase_redis"
 	"fmt"
 	"net/http"
 	"os"
@@ -84,26 +85,36 @@ var fsmPlanners = map[SectorState]func(events []statemachine.Event, state *Secto
 		on(SectorReceive{}, ReceiveSector),
 	),
 	Empty: planOne( // deprecated
+		on(SectorAddPieceWait{}, WaitAP),
 		on(SectorAddPiece{}, AddPiece),
 		on(SectorStartPacking{}, Packing),
 	),
 	WaitDeals: planOne(
+		on(SectorAddPieceWait{}, WaitAP),
 		on(SectorAddPiece{}, AddPiece),
 		on(SectorStartPacking{}, Packing),
 	),
+	Recover: planOne(
+		on(SectorAddPieceWait{}, WaitAP),
+	),
+	WaitAP: planOne(),
 	AddPiece: planOne(
 		on(SectorPieceAdded{}, WaitDeals),
+		on(SectorWaitPC{}, WaitPC),
 		apply(SectorStartPacking{}),
 		apply(SectorAddPiece{}),
 		on(SectorAddPieceFailed{}, AddPieceFailed),
 	),
 	Packing: planOne(on(SectorPacked{}, GetTicket)),
 	GetTicket: planOne(
-		on(SectorTicket{}, PreCommit1),
+		// on(SectorTicket{}, PreCommit1),
+		on(SectorTicket{}, WaitPC),
 		on(SectorCommitFailed{}, CommitFailed),
 	),
+	WaitPC: planOne(),
 	PreCommit1: planOne(
 		on(SectorPreCommit1{}, PreCommit2),
+		on(SectorWaitAP{}, WaitAP),
 		on(SectorSealPreCommit1Failed{}, SealPreCommit1Failed),
 		on(SectorDealsExpired{}, DealsExpired),
 		on(SectorInvalidDealIDs{}, RecoverDealIDs),
@@ -111,8 +122,10 @@ var fsmPlanners = map[SectorState]func(events []statemachine.Event, state *Secto
 	),
 	PreCommit2: planOne(
 		on(SectorPreCommit2{}, SubmitPreCommitBatch),
+		on(SectorWaitAP{}, WaitAP),
 		on(SectorSealPreCommit2Failed{}, SealPreCommit2Failed),
 		on(SectorSealPreCommit1Failed{}, SealPreCommit1Failed),
+		on(SectorWaitCommitFinalize{}, WaitCommitFinalize),
 	),
 	PreCommitting: planOne(
 		on(SectorPreCommitBatch{}, SubmitPreCommitBatch),
@@ -142,14 +155,18 @@ var fsmPlanners = map[SectorState]func(events []statemachine.Event, state *Secto
 		on(SectorRetryPreCommit{}, PreCommitting),
 	),
 	WaitSeed: planOne(
-		on(SectorSeedReady{}, Committing),
+		// on(SectorSeedReady{}, Committing),
+		on(SectorSeedReady{}, WaitC),
 		on(SectorChainPreCommitFailed{}, PreCommitFailed),
 	),
-	Committing: planCommitting,
+	WaitC:              planOne(),
+	Committing:         planCommitting,
+	WaitCommitFinalize: planOne(),
 	CommitFinalize: planOne(
 		on(SectorFinalized{}, SubmitCommitAggregate),
 		on(SectorFinalizedAvailable{}, SubmitCommitAggregate),
 		on(SectorFinalizeFailed{}, CommitFinalizeFailed),
+		onWithCB(SectorRecoverFinalized{}, Proving, maybeNotifyRemoteDone(true, "Proving")),
 	),
 	SubmitCommit: planOne(
 		on(SectorCommitSubmitted{}, CommitWait),
@@ -163,11 +180,13 @@ var fsmPlanners = map[SectorState]func(events []statemachine.Event, state *Secto
 	),
 	CommitWait: planOne(
 		on(SectorProving{}, FinalizeSector),
+		on(SectorWaitProving{}, WaitCommitFinalize),
 		on(SectorCommitFailed{}, CommitFailed),
 		on(SectorRetrySubmitCommit{}, SubmitCommit),
 	),
 	CommitAggregateWait: planOne(
 		on(SectorProving{}, FinalizeSector),
+		on(SectorWaitProving{}, WaitCommitFinalize),
 		on(SectorCommitFailed{}, CommitFailed),
 		on(SectorRetrySubmitCommit{}, SubmitCommit),
 	),
@@ -510,12 +529,18 @@ func (m *Sealing) plan(events []statemachine.Event, state *SectorInfo) (func(sta
 		fallthrough
 	case WaitDeals:
 		return m.handleWaitDeals, processed, nil
+	case Recover:
+		return m.handleRecover, processed, nil
+	case WaitAP:
+		return m.handleWaitAP, processed, nil
 	case AddPiece:
 		return m.handleAddPiece, processed, nil
 	case Packing:
 		return m.handlePacking, processed, nil
 	case GetTicket:
 		return m.handleGetTicket, processed, nil
+	case WaitPC:
+		return m.handleWaitPC, processed, nil
 	case PreCommit1:
 		return m.handlePreCommit1, processed, nil
 	case PreCommit2:
@@ -530,8 +555,12 @@ func (m *Sealing) plan(events []statemachine.Event, state *SectorInfo) (func(sta
 		return m.handlePreCommitWait, processed, nil
 	case WaitSeed:
 		return m.handleWaitSeed, processed, nil
+	case WaitC:
+		return m.handleWaitC, processed, nil
 	case Committing:
 		return m.handleCommitting, processed, nil
+	case WaitCommitFinalize:
+		return m.handleWaitCommitFinalize, processed, nil
 	case SubmitCommit:
 		return m.handleSubmitCommit, processed, nil
 	case SubmitCommitAggregate:
@@ -698,6 +727,9 @@ func planCommitting(events []statemachine.Event, state *SectorInfo) (uint64, err
 		case SectorProofReady: // early finalize
 			e.apply(state)
 			state.State = CommitFinalize
+		case SectorWaitCommitFinalize: // early finalize
+			e.apply(state)
+			state.State = WaitCommitFinalize
 		case SectorSeedReady: // seed changed :/
 			if e.SeedEpoch == state.SeedEpoch && bytes.Equal(e.SeedValue, state.SeedValue) {
 				log.Warnf("planCommitting: got SectorSeedReady, but the seed didn't change")
@@ -708,6 +740,8 @@ func planCommitting(events []statemachine.Event, state *SectorInfo) (uint64, err
 			e.apply(state)
 			state.State = Committing
 			return uint64(i + 1), nil
+		case SectorWaitC:
+			state.State = WaitC
 		case SectorComputeProofFailed:
 			state.State = ComputeProofFailed
 		case SectorRemoteCommit1Failed, SectorRemoteCommit2Failed:
@@ -749,6 +783,43 @@ func (m *Sealing) ForceSectorState(ctx context.Context, id abi.SectorNumber, sta
 	return m.sectors.Send(id, SectorForceState{state})
 }
 
+func (m *Sealing) ForceSectorStateOfSxx(ctx context.Context, id abi.SectorNumber, state SectorState, worker string) error {
+	log.Infof("ForceSectorStateOfSxx : sector %+v , state %+v, worker : %+v", id, state, worker)
+	_, err := m.SectorsStatus(ctx, id, false)
+	if err != nil {
+		return xerrors.Errorf("sector %d not found, could not change state", id)
+	}
+	if state == SectorState("AddPiece") {
+		// 将扇区对应的worker记录到radis中。
+		_, err = filbase_redis.SetWorkerForSector(filbase_redis.PWorkerKey, id.String(), worker)
+		if err != nil {
+			return xerrors.Errorf("fail to set worker into radis for sector %+v", id)
+		}
+	}
+	if state == SectorState("Committing") {
+		// 将扇区对应的worker记录到radis中。
+		_, err = filbase_redis.SetWorkerForSector(filbase_redis.CWorkerKey, id.String(), worker)
+		if err != nil {
+			return xerrors.Errorf("fail to set worker into radis for sector %+v", id)
+		}
+	}
+
+	if state == SectorState("CommitFinalize") || state == SectorState("FinalizeSector") {
+		cfg, err := m.getConfig()
+		if err != nil {
+			return xerrors.Errorf("getting config: %w", err)
+		}
+		if cfg.FinalizeEarly {
+			state = SectorState("CommitFinalize")
+		} else {
+			state = SectorState("FinalizeSector")
+		}
+	}
+
+	m.startupWait.Wait()
+	return m.sectors.Send(id, SectorForceState{state})
+}
+
 // as sector has been removed, it's no needs to care about later events,
 // just returns length of events as `processed` is ok.
 func finalRemoved(events []statemachine.Event, state *SectorInfo) (uint64, error) {
diff --git a/storage/pipeline/fsm_events.go b/storage/pipeline/fsm_events.go
index 94cd53e82..448ad06d1 100644
--- a/storage/pipeline/fsm_events.go
+++ b/storage/pipeline/fsm_events.go
@@ -87,6 +87,40 @@ func (evt SectorAddPiece) apply(state *SectorInfo) {
 	}
 }
 
+type SectorAddPieceWait struct{}
+
+func (evt SectorAddPieceWait) apply(si *SectorInfo) {}
+
+type SectorRecover struct{}
+
+func (evt SectorRecover) apply(*SectorInfo) {}
+
+type SectorWaitAP struct{}
+
+func (evt SectorWaitAP) apply(*SectorInfo) {}
+
+type SectorWaitPC struct{}
+
+func (evt SectorWaitPC) apply(*SectorInfo) {}
+
+type SectorWaitC struct{}
+
+func (evt SectorWaitC) apply(*SectorInfo) {}
+
+type SectorWaitCommitFinalize struct {
+	Proof []byte
+}
+
+func (evt SectorWaitCommitFinalize) apply(state *SectorInfo) {
+	state.Proof = evt.Proof
+}
+
+type SectorRecoverFinalized struct {
+	Proof []byte
+}
+
+func (evt SectorRecoverFinalized) apply(state *SectorInfo) {}
+
 type SectorPieceAdded struct {
 	NewPieces []SafeSectorPiece
 }
@@ -297,6 +331,10 @@ type SectorProving struct{}
 
 func (evt SectorProving) apply(*SectorInfo) {}
 
+type SectorWaitProving struct{}
+
+func (evt SectorWaitProving) apply(*SectorInfo) {}
+
 type SectorFinalized struct{}
 
 func (evt SectorFinalized) apply(*SectorInfo) {}
diff --git a/storage/pipeline/input.go b/storage/pipeline/input.go
index 6d41f7e81..776b1ca0a 100644
--- a/storage/pipeline/input.go
+++ b/storage/pipeline/input.go
@@ -26,8 +26,18 @@ import (
 	"github.com/filecoin-project/lotus/storage/sealer/ffiwrapper"
 	"github.com/filecoin-project/lotus/storage/sealer/storiface"
 	"github.com/filecoin-project/lotus/storage/sectorblocks"
+
+	"encoding/json"
+	"os"
+	"strings"
+
+	scClient "github.com/moran666666/sector-counter/client"
 )
 
+type MessageOfSxx struct {
+	User SectorPieceAdded
+}
+
 func (m *Sealing) handleWaitDeals(ctx statemachine.Context, sector SectorInfo) error {
 	var used abi.UnpaddedPieceSize
 	var lastDealEnd abi.ChainEpoch
@@ -59,6 +69,9 @@ func (m *Sealing) handleWaitDeals(ctx statemachine.Context, sector SectorInfo) e
 	if len(m.assignedPieces[sid]) > 0 {
 		m.inputLk.Unlock()
 		// got assigned more pieces in the AddPiece state
+		if os.Getenv("LOTUS_OF_SXX") == "1" {
+			return ctx.Send(SectorAddPieceWait{})
+		}
 		return ctx.Send(SectorAddPiece{})
 	}
 
@@ -78,6 +91,9 @@ func (m *Sealing) handleWaitDeals(ctx statemachine.Context, sector SectorInfo) e
 				// todo check deal start deadline (configurable)
 				m.assignedPieces[sid] = append(m.assignedPieces[sid], pk)
 
+				if os.Getenv("LOTUS_OF_SXX") == "1" {
+					return ctx.Send(SectorAddPieceWait{})
+				}
 				return ctx.Send(SectorAddPiece{})
 			},
 			number:   sector.SectorNumber,
@@ -100,6 +116,10 @@ func (m *Sealing) handleWaitDeals(ctx statemachine.Context, sector SectorInfo) e
 	return nil
 }
 
+func (m *Sealing) handleRecover(ctx statemachine.Context, sector SectorInfo) error {
+	return ctx.Send(SectorAddPieceWait{})
+}
+
 func (m *Sealing) maybeStartSealing(ctx statemachine.Context, sector SectorInfo, used abi.UnpaddedPieceSize) (bool, error) {
 	log := log.WithOptions(zap.Fields(
 		zap.Uint64("sector", uint64(sector.SectorNumber)),
@@ -224,6 +244,34 @@ func (m *Sealing) handleAddPiece(ctx statemachine.Context, sector SectorInfo) er
 	m.inputLk.Unlock()
 	if !ok {
 		// nothing to do here (might happen after a restart in AddPiece)
+		if len(sector.Pieces) > 0 {
+			info, err := m.GetSectorInfo(sector.SectorNumber)
+			if err != nil {
+				return ctx.Send(SectorAddPieceFailed{err})
+			}
+			for _, l := range info.Log {
+				if l.Kind == "event;sealing.SectorPieceAdded" {
+					pieceSizes := make([]abi.UnpaddedPieceSize, 0)
+					var messageOfSxx MessageOfSxx
+					if err = json.Unmarshal([]byte(l.Message), &messageOfSxx); err != nil {
+						return ctx.Send(SectorAddPieceFailed{err})
+					}
+					for _, p := range messageOfSxx.User.NewPieces {
+						_, err := m.sealer.AddPieceOfSxx(sealer.WithPriority(ctx.Context(), DealSectorPriority),
+							m.minerSector(sector.SectorType, sector.SectorNumber),
+							pieceSizes,
+							p.Piece().Size.Unpadded(),
+							p.DealInfo().GetRemoteFilepath())
+						if err != nil {
+							err = xerrors.Errorf("writing piece: %w", err)
+							return ctx.Send(SectorAddPieceFailed{err})
+						}
+					}
+					break
+				}
+			}
+			return ctx.Send(SectorWaitPC{})
+		}
 		return ctx.Send(res)
 	}
 
@@ -290,16 +338,55 @@ func (m *Sealing) handleAddPiece(ctx statemachine.Context, sector SectorInfo) er
 			})
 		}
 
-		ppi, err := m.sealer.AddPiece(sealer.WithPriority(ctx.Context(), DealSectorPriority),
-			m.minerSector(sector.SectorType, sector.SectorNumber),
-			pieceSizes,
-			deal.size,
-			deal.data)
-		if err != nil {
-			err = xerrors.Errorf("writing piece: %w", err)
-			deal.accepted(sector.SectorNumber, offset, err)
-			return ctx.Send(SectorAddPieceFailed{err})
+		// ppi, err := m.sealer.AddPiece(sealer.WithPriority(ctx.Context(), DealSectorPriority),
+		//      m.minerSector(sector.SectorType, sector.SectorNumber),
+		//      pieceSizes,
+		//      deal.size,
+		//      deal.data)
+		// if err != nil {
+		//      err = xerrors.Errorf("writing piece: %w", err)
+		//      deal.accepted(sector.SectorNumber, offset, err)
+		//      return ctx.Send(SectorAddPieceFailed{err})
+		// }
+		// change by lin
+		var ppi abi.PieceInfo
+		if os.Getenv("LOTUS_OF_SXX") == "1" && deal.deal.GetRemoteFilepath() != "" {
+			if !strings.HasPrefix(string(deal.deal.GetRemoteFilepath()), "/") {
+				ppi, err = m.sealer.AddPiece(sealer.WithPriority(ctx.Context(), DealSectorPriority),
+					m.minerSector(sector.SectorType, sector.SectorNumber),
+					pieceSizes,
+					deal.size,
+					deal.data)
+				if err != nil {
+					err = xerrors.Errorf("writing piece: %w", err)
+					deal.accepted(sector.SectorNumber, offset, err)
+					return ctx.Send(SectorAddPieceFailed{err})
+				}
+			} else {
+				ppi, err = m.sealer.AddPieceOfSxx(sealer.WithPriority(ctx.Context(), DealSectorPriority),
+					m.minerSector(sector.SectorType, sector.SectorNumber),
+					pieceSizes,
+					deal.size,
+					deal.deal.GetRemoteFilepath())
+				if err != nil {
+					err = xerrors.Errorf("writing piece: %w", err)
+					deal.accepted(sector.SectorNumber, offset, err)
+					return ctx.Send(SectorAddPieceFailed{err})
+				}
+			}
+		} else {
+			ppi, err = m.sealer.AddPiece(sealer.WithPriority(ctx.Context(), DealSectorPriority),
+				m.minerSector(sector.SectorType, sector.SectorNumber),
+				pieceSizes,
+				deal.size,
+				deal.data)
+			if err != nil {
+				err = xerrors.Errorf("writing piece: %w", err)
+				deal.accepted(sector.SectorNumber, offset, err)
+				return ctx.Send(SectorAddPieceFailed{err})
+			}
 		}
+		// end
 		if !ppi.PieceCID.Equals(deal.deal.PieceCID()) {
 			err = xerrors.Errorf("got unexpected piece CID: expected:%s, got:%s", deal.deal.PieceCID(), ppi.PieceCID)
 			deal.accepted(sector.SectorNumber, offset, err)
@@ -845,12 +932,28 @@ func (m *Sealing) maybeUpgradeSector(ctx context.Context, sp abi.RegisteredSealP
 
 // call with m.inputLk
 func (m *Sealing) createSector(ctx context.Context, cfg sealiface.Config, sp abi.RegisteredSealProof) (abi.SectorNumber, error) {
-	sid, err := m.NextSectorNumber(ctx)
-	if err != nil {
-		return 0, xerrors.Errorf("getting sector number: %w", err)
+	// sid, err := m.NextSectorNumber(ctx)
+	// if err != nil {
+	// 	return 0, xerrors.Errorf("getting sector number: %w", err)
+	// }
+
+	// change by sxx
+	var sid abi.SectorNumber
+	if _, ok := os.LookupEnv("SC_TYPE"); ok {
+		sid0, err := scClient.NewClient().GetSectorID(context.Background(), "")
+		if err != nil {
+			return 0, xerrors.Errorf("getting sector number: %w", err)
+		}
+		sid = abi.SectorNumber(sid0)
+	} else {
+		sid0, err := m.NextSectorNumber(ctx)
+		if err != nil {
+			return 0, xerrors.Errorf("getting sector number: %w", err)
+		}
+		sid = sid0
 	}
 
-	err = m.sealer.NewSector(ctx, m.minerSector(sp, sid))
+	err := m.sealer.NewSector(ctx, m.minerSector(sp, sid))
 	if err != nil {
 		return 0, xerrors.Errorf("initializing sector: %w", err)
 	}
diff --git a/storage/pipeline/piece/piece_info.go b/storage/pipeline/piece/piece_info.go
index 7ee8f7029..6f6dcba1e 100644
--- a/storage/pipeline/piece/piece_info.go
+++ b/storage/pipeline/piece/piece_info.go
@@ -34,6 +34,8 @@ type PieceDealInfo struct {
 
 	// Best-effort deal asks
 	KeepUnsealed bool
+
+	RemoteFilepath string
 }
 
 // DealSchedule communicates the time interval of a storage deal. The deal must
@@ -174,6 +176,10 @@ func (ds *PieceDealInfo) KeepUnsealedRequested() bool {
 	return ds.KeepUnsealed
 }
 
+func (ds *PieceDealInfo) GetRemoteFilepath() string {
+	return ds.RemoteFilepath
+}
+
 type PieceKey string
 
 // Key returns a unique identifier for this deal info, for use in maps.
diff --git a/storage/pipeline/sector_state.go b/storage/pipeline/sector_state.go
index 9e7f75171..43c4c7281 100644
--- a/storage/pipeline/sector_state.go
+++ b/storage/pipeline/sector_state.go
@@ -66,6 +66,11 @@ var ExistSectorStateList = map[SectorState]struct{}{
 	FinalizeReplicaUpdateFailed: {},
 	AbortUpgrade:                {},
 	ReceiveSector:               {},
+	Recover:                     {},
+	WaitAP:                      {},
+	WaitPC:                      {},
+	WaitC:                       {},
+	WaitCommitFinalize:          {},
 }
 
 // cmd/lotus-miner/info.go defines CLI colors corresponding to these states
@@ -155,6 +160,12 @@ const (
 	Removing     SectorState = "Removing"
 	RemoveFailed SectorState = "RemoveFailed"
 	Removed      SectorState = "Removed"
+
+	Recover            SectorState = "Recover"
+	WaitAP             SectorState = "WaitAP"
+	WaitPC             SectorState = "WaitPC"
+	WaitC              SectorState = "WaitC"
+	WaitCommitFinalize SectorState = "WaitCommitFinalize"
 )
 
 func toStatState(st SectorState, finEarly bool) statSectorState {
diff --git a/storage/pipeline/states_sealing.go b/storage/pipeline/states_sealing.go
index 4f40ac7c7..2e8696fbb 100644
--- a/storage/pipeline/states_sealing.go
+++ b/storage/pipeline/states_sealing.go
@@ -7,6 +7,7 @@ import (
 	"errors"
 	"io"
 	"net/http"
+	"os"
 	"time"
 
 	"github.com/ipfs/go-cid"
@@ -35,6 +36,9 @@ import (
 	"github.com/filecoin-project/lotus/chain/types"
 	"github.com/filecoin-project/lotus/storage/pipeline/lib/nullreader"
 	"github.com/filecoin-project/lotus/storage/sealer/storiface"
+
+	"fmt"
+	"strings"
 )
 
 const MinDDONetworkVersion = network.Version22
@@ -201,25 +205,42 @@ func (m *Sealing) getTicket(ctx statemachine.Context, sector SectorInfo) (abi.Se
 }
 
 func (m *Sealing) handleGetTicket(ctx statemachine.Context, sector SectorInfo) error {
-	ticketValue, ticketEpoch, allocated, err := m.getTicket(ctx, sector)
-	if err != nil {
-		if allocated {
-			if sector.CommitMessage != nil {
-				// Some recovery paths with unfortunate timing lead here
-				return ctx.Send(SectorCommitFailed{xerrors.Errorf("sector %s is committed but got into the GetTicket state", sector.SectorNumber)})
+	if os.Getenv("LOTUS_OF_RECOVER") == "1" {
+		info, err := m.GetSectorInfo(sector.SectorNumber)
+		if err != nil {
+			return ctx.Send(SectorSealPreCommit1Failed{xerrors.Errorf("getting ticket failed: %w", err)})
+		}
+		var st SectorTicket
+		for _, l := range info.Log {
+			if l.Kind == "event;sealing.SectorTicket" {
+				if err = json.Unmarshal([]byte(l.Message), &st); err != nil {
+					return ctx.Send(SectorSealPreCommit1Failed{xerrors.Errorf("getting ticket failed: %w", err)})
+				}
+				break
+			}
+		}
+		return ctx.Send(st)
+	} else {
+		ticketValue, ticketEpoch, allocated, err := m.getTicket(ctx, sector)
+		if err != nil {
+			if allocated {
+				if sector.CommitMessage != nil {
+					// Some recovery paths with unfortunate timing lead here
+					return ctx.Send(SectorCommitFailed{xerrors.Errorf("sector %s is committed but got into the GetTicket state", sector.SectorNumber)})
+				}
+
+				log.Errorf("Sector %s precommitted but expired", sector.SectorNumber)
+				return ctx.Send(SectorRemove{})
 			}
 
-			log.Errorf("Sector %s precommitted but expired", sector.SectorNumber)
-			return ctx.Send(SectorRemove{})
+			return ctx.Send(SectorSealPreCommit1Failed{xerrors.Errorf("getting ticket failed: %w", err)})
 		}
 
-		return ctx.Send(SectorSealPreCommit1Failed{xerrors.Errorf("getting ticket failed: %w", err)})
+		return ctx.Send(SectorTicket{
+			TicketValue: ticketValue,
+			TicketEpoch: ticketEpoch,
+		})
 	}
-
-	return ctx.Send(SectorTicket{
-		TicketValue: ticketValue,
-		TicketEpoch: ticketEpoch,
-	})
 }
 
 var SoftErrRetryWait = 5 * time.Second
@@ -258,7 +279,36 @@ func retrySoftErr(ctx context.Context, cb func() error) error {
 	}
 }
 
+func (m *Sealing) handleWaitAP(ctx statemachine.Context, sector SectorInfo) error {
+	return nil
+}
+
+func (m *Sealing) handleWaitPC(ctx statemachine.Context, sector SectorInfo) error {
+	return nil
+}
+
+func (m *Sealing) handleWaitC(ctx statemachine.Context, sector SectorInfo) error {
+	return nil
+}
+
+func (m *Sealing) handleWaitCommitFinalize(ctx statemachine.Context, sector SectorInfo) error {
+	return nil
+}
+
 func (m *Sealing) handlePreCommit1(ctx statemachine.Context, sector SectorInfo) error {
+	if os.Getenv("LOTUS_OF_RECOVER") == "1" {
+		pc1o, err := m.sealer.SealPreCommit1(sector.sealingCtx(ctx.Context()), m.minerSector(sector.SectorType, sector.SectorNumber), sector.TicketValue, sector.pieceInfos())
+		if err != nil {
+			if strings.Contains(fmt.Sprintf("%s", err), "task aborted") {
+				return ctx.Send(SectorWaitAP{})
+			}
+			return ctx.Send(SectorSealPreCommit1Failed{xerrors.Errorf("seal pre commit(1) failed: %w", err)})
+		}
+
+		return ctx.Send(SectorPreCommit1{
+			PreCommit1Out: pc1o,
+		})
+	}
 	if err := checkPieces(ctx.Context(), m.maddr, sector.SectorNumber, sector.Pieces, m.Api, false); err != nil { // Sanity check state
 		switch err.(type) {
 		case *ErrApi:
@@ -320,6 +370,9 @@ func (m *Sealing) handlePreCommit1(ctx statemachine.Context, sector SectorInfo)
 		return err
 	})
 	if err != nil {
+		if strings.Contains(fmt.Sprintf("%s", err), "task aborted") {
+			return ctx.Send(SectorWaitAP{})
+		}
 		return ctx.Send(SectorSealPreCommit1Failed{xerrors.Errorf("seal pre commit(1) failed: %w", err)})
 	}
 
@@ -336,6 +389,9 @@ func (m *Sealing) handlePreCommit2(ctx statemachine.Context, sector SectorInfo)
 		return err
 	})
 	if err != nil {
+		if strings.Contains(fmt.Sprintf("%s", err), "task aborted") {
+			return ctx.Send(SectorWaitAP{})
+		}
 		return ctx.Send(SectorSealPreCommit2Failed{xerrors.Errorf("seal pre commit(2) failed: %w", err)})
 	}
 
@@ -343,6 +399,13 @@ func (m *Sealing) handlePreCommit2(ctx statemachine.Context, sector SectorInfo)
 		return ctx.Send(SectorSealPreCommit1Failed{xerrors.Errorf("seal pre commit(2) returned undefined CommD")})
 	}
 
+	if os.Getenv("LOTUS_OF_RECOVER") == "1" {
+		var porepProof storiface.Proof
+		return ctx.Send(SectorWaitCommitFinalize{
+			Proof: porepProof,
+		})
+	}
+
 	return ctx.Send(SectorPreCommit2{
 		Unsealed: cids.Unsealed,
 		Sealed:   cids.Sealed,
@@ -628,6 +691,9 @@ func (m *Sealing) handleCommitting(ctx statemachine.Context, sector SectorInfo)
 		}
 		c2in, err = m.sealer.SealCommit1(sector.sealingCtx(ctx.Context()), m.minerSector(sector.SectorType, sector.SectorNumber), sector.TicketValue, sector.SeedValue, sector.pieceInfos(), cids)
 		if err != nil {
+			if strings.Contains(fmt.Sprintf("%s", err), "task aborted") {
+				return ctx.Send(SectorWaitC{})
+			}
 			return ctx.Send(SectorComputeProofFailed{xerrors.Errorf("computing seal proof failed(1): %w", err)})
 		}
 	} else {
@@ -676,6 +742,9 @@ func (m *Sealing) handleCommitting(ctx statemachine.Context, sector SectorInfo)
 		porepProof, err = m.sealer.SealCommit2(sector.sealingCtx(ctx.Context()), m.minerSector(sector.SectorType, sector.SectorNumber), c2in)
 		if err != nil {
 			log.Errorw("Commit2 error", "error", err)
+			if strings.Contains(fmt.Sprintf("%s", err), "task aborted") {
+				return ctx.Send(SectorWaitC{})
+			}
 			return ctx.Send(SectorComputeProofFailed{xerrors.Errorf("computing seal proof failed(2): %w", err)})
 		}
 	} else {
@@ -728,6 +797,11 @@ func (m *Sealing) handleCommitting(ctx statemachine.Context, sector SectorInfo)
 	}
 
 	if cfg.FinalizeEarly {
+		if os.Getenv("LOTUS_OF_SXX") == "1" {
+			return ctx.Send(SectorWaitCommitFinalize{
+				Proof: porepProof,
+			})
+		}
 		return ctx.Send(SectorProofReady{
 			Proof: porepProof,
 		})
@@ -926,6 +1000,14 @@ func (m *Sealing) handleCommitWait(ctx statemachine.Context, sector SectorInfo)
 		return ctx.Send(SectorCommitFailed{xerrors.Errorf("proof validation failed, sector not found in sector set after cron")})
 	}
 
+	cfg, err := m.getConfig()
+	if err != nil {
+		return xerrors.Errorf("getting config: %w", err)
+	}
+	if !cfg.FinalizeEarly && os.Getenv("LOTUS_OF_SXX") == "1" {
+		return ctx.Send(SectorWaitProving{})
+	}
+
 	return ctx.Send(SectorProving{})
 }
 
@@ -945,6 +1027,10 @@ func (m *Sealing) handleFinalizeSector(ctx statemachine.Context, sector SectorIn
 		return ctx.Send(SectorFinalizeFailed{xerrors.Errorf("finalize sector: %w", err)})
 	}
 
+	if os.Getenv("LOTUS_OF_RECOVER") == "1" {
+		return ctx.Send(SectorRecoverFinalized{})
+	}
+
 	if cfg.MakeCCSectorsAvailable && !sector.hasData() {
 		return ctx.Send(SectorFinalizedAvailable{})
 	}
diff --git a/storage/pipeline/types.go b/storage/pipeline/types.go
index 7b263dd6a..8b81b04ea 100644
--- a/storage/pipeline/types.go
+++ b/storage/pipeline/types.go
@@ -59,6 +59,7 @@ type UniversalPieceInfo interface {
 	KeepUnsealedRequested() bool
 
 	GetAllocation(ctx context.Context, aapi piece.AllocationAPI, tsk types.TipSetKey) (*verifreg.Allocation, error)
+	GetRemoteFilepath() string
 }
 
 type SectorInfo struct {
@@ -351,3 +352,11 @@ func (sp *SafeSectorPiece) GetAllocation(ctx context.Context, aapi piece.Allocat
 
 	return sp.real.DealInfo.GetAllocation(ctx, aapi, tsk)
 }
+
+func (sp *SafeSectorPiece) GetRemoteFilepath() string {
+	if !sp.HasDealInfo() {
+		return sp.real.DealInfo.RemoteFilepath
+	}
+
+	return sp.real.DealInfo.GetRemoteFilepath()
+}
diff --git a/storage/sealer/faults.go b/storage/sealer/faults.go
index add2acf96..04adf8364 100644
--- a/storage/sealer/faults.go
+++ b/storage/sealer/faults.go
@@ -12,11 +12,17 @@ import (
 	"github.com/filecoin-project/go-state-types/abi"
 
 	"github.com/filecoin-project/lotus/storage/sealer/storiface"
+
+	"os"
+	"path/filepath"
+
+	"github.com/filecoin-project/specs-actors/actors/runtime/proof"
 )
 
 // FaultTracker TODO: Track things more actively
 type FaultTracker interface {
 	CheckProvable(ctx context.Context, pp abi.RegisteredPoStProof, sectors []storiface.SectorRef, rg storiface.RGetter) (map[abi.SectorID]string, error)
+	CheckProve(ctx context.Context, pp abi.RegisteredPoStProof, sectors []storiface.SectorRef, update []bool, rg storiface.RGetter) (map[abi.SectorID]string, error)
 }
 
 // CheckProvable returns unprovable sectors
@@ -135,3 +141,160 @@ func (m *Manager) CheckProvable(ctx context.Context, pp abi.RegisteredPoStProof,
 }
 
 var _ FaultTracker = &Manager{}
+
+// CheckProve returns unprovable sectors
+func (m *Manager) CheckProve(ctx context.Context, pp abi.RegisteredPoStProof, sectors []storiface.SectorRef, update []bool, rg storiface.RGetter) (map[abi.SectorID]string, error) {
+	var bad = make(map[abi.SectorID]string)
+
+	ssize, err := pp.SectorSize()
+	if err != nil {
+		return nil, err
+	}
+
+	// TODO: More better checks
+	for i, sector := range sectors {
+		err := func() error {
+			ctx, cancel := context.WithCancel(ctx)
+			defer cancel()
+			var fReplica string
+			var fCache string
+
+			if update[i] {
+				lockedUpdate, err := m.index.StorageTryLock(ctx, sector.ID, storiface.FTUpdate|storiface.FTUpdateCache, storiface.FTNone)
+				if err != nil {
+					return xerrors.Errorf("acquiring sector lock: %w", err)
+				}
+				if !lockedUpdate {
+					log.Warnw("CheckProvable Sector FAULT: can't acquire read lock on update replica", "sector", sector)
+					bad[sector.ID] = fmt.Sprint("can't acquire read lock")
+					return nil
+				}
+				lp, _, err := m.localStore.AcquireSector(ctx, sector, storiface.FTUpdate|storiface.FTUpdateCache, storiface.FTNone, storiface.PathStorage, storiface.AcquireMove)
+				if err != nil {
+					log.Warnw("CheckProvable Sector FAULT: acquire sector update replica in checkProvable", "sector", sector, "error", err)
+					bad[sector.ID] = fmt.Sprintf("acquire sector failed: %s", err)
+					return nil
+				}
+				fReplica, fCache = lp.Update, lp.UpdateCache
+			} else {
+				locked, err := m.index.StorageTryLock(ctx, sector.ID, storiface.FTSealed|storiface.FTCache, storiface.FTNone)
+				if err != nil {
+					return xerrors.Errorf("acquiring sector lock: %w", err)
+				}
+
+				if !locked {
+					log.Warnw("CheckProvable Sector FAULT: can't acquire read lock", "sector", sector)
+					bad[sector.ID] = fmt.Sprint("can't acquire read lock")
+					return nil
+				}
+
+				lp, _, err := m.localStore.AcquireSector(ctx, sector, storiface.FTSealed|storiface.FTCache, storiface.FTNone, storiface.PathStorage, storiface.AcquireMove)
+				if err != nil {
+					log.Warnw("CheckProvable Sector FAULT: acquire sector in checkProvable", "sector", sector, "error", err)
+					bad[sector.ID] = fmt.Sprintf("acquire sector failed: %s", err)
+					return nil
+				}
+				fReplica, fCache = lp.Sealed, lp.Cache
+			}
+			if fReplica == "" || fCache == "" {
+				log.Warnw("CheckProvable Sector FAULT: cache and/or sealed paths not found", "sector", sector, "sealed", fReplica, "cache", fCache)
+				bad[sector.ID] = fmt.Sprintf("cache and/or sealed paths not found, cache %q, sealed %q", fCache, fReplica)
+				return nil
+			}
+
+			toCheck := map[string]int64{
+				fReplica:                       1,
+				filepath.Join(fCache, "p_aux"): 0,
+			}
+
+			addCachePathsForSectorSize(toCheck, fCache, ssize)
+
+			for p, sz := range toCheck {
+				st, err := os.Stat(p)
+				if err != nil {
+					log.Warnw("CheckProvable Sector FAULT: sector file stat error", "sector", sector, "sealed", fReplica, "cache", fCache, "file", p, "err", err)
+					bad[sector.ID] = fmt.Sprintf("%s", err)
+					return nil
+				}
+
+				if sz != 0 {
+					if st.Size() != int64(ssize)*sz {
+						log.Warnw("CheckProvable Sector FAULT: sector file is wrong size", "sector", sector, "sealed", fReplica, "cache", fCache, "file", p, "size", st.Size(), "expectSize", int64(ssize)*sz)
+						bad[sector.ID] = fmt.Sprintf("%s is wrong size (got %d, expect %d)", p, st.Size(), int64(ssize)*sz)
+						return nil
+					}
+				}
+			}
+
+			if rg != nil {
+				wpp, err := sector.ProofType.RegisteredWindowPoStProof()
+				if err != nil {
+					return err
+				}
+
+				var pr abi.PoStRandomness = make([]byte, abi.RandomnessLength)
+				_, _ = rand.Read(pr)
+				pr[31] &= 0x3f
+
+				ch, err := ffi.GeneratePoStFallbackSectorChallenges(wpp, sector.ID.Miner, pr, []abi.SectorNumber{
+					sector.ID.Number,
+				})
+				if err != nil {
+					log.Warnw("CheckProvable Sector FAULT: generating challenges", "sector", sector, "sealed", fReplica, "cache", fCache, "err", err)
+					bad[sector.ID] = fmt.Sprintf("generating fallback challenges: %s", err)
+					return nil
+				}
+
+				commr, _, err := rg(ctx, sector.ID)
+				if err != nil {
+					log.Warnw("CheckProvable Sector FAULT: getting commR", "sector", sector, "sealed", fReplica, "cache", fCache, "err", err)
+					bad[sector.ID] = fmt.Sprintf("getting commR: %s", err)
+					return nil
+				}
+				_, err = ffi.GenerateSingleVanillaProof(ffi.PrivateSectorInfo{
+					SectorInfo: proof.SectorInfo{
+						SealProof:    sector.ProofType,
+						SectorNumber: sector.ID.Number,
+						SealedCID:    commr,
+					},
+					CacheDirPath:     fCache,
+					PoStProofType:    wpp,
+					SealedSectorPath: fReplica,
+				}, ch.Challenges[sector.ID.Number])
+				if err != nil {
+					log.Warnw("CheckProvable Sector FAULT: generating vanilla proof", "sector", sector, "sealed", fReplica, "cache", fCache, "err", err)
+					bad[sector.ID] = fmt.Sprintf("generating vanilla proof: %s", err)
+					return nil
+				}
+			}
+
+			return nil
+		}()
+		if err != nil {
+			return nil, err
+		}
+	}
+
+	return bad, nil
+}
+
+func addCachePathsForSectorSize(chk map[string]int64, cacheDir string, ssize abi.SectorSize) {
+	switch ssize {
+	case 2 << 10:
+		fallthrough
+	case 8 << 20:
+		fallthrough
+	case 512 << 20:
+		chk[filepath.Join(cacheDir, "sc-02-data-tree-r-last.dat")] = 0
+	case 32 << 30:
+		for i := 0; i < 8; i++ {
+			chk[filepath.Join(cacheDir, fmt.Sprintf("sc-02-data-tree-r-last-%d.dat", i))] = 0
+		}
+	case 64 << 30:
+		for i := 0; i < 16; i++ {
+			chk[filepath.Join(cacheDir, fmt.Sprintf("sc-02-data-tree-r-last-%d.dat", i))] = 0
+		}
+	default:
+		log.Warnf("not checking cache files of %s sectors for faults", ssize)
+	}
+}
diff --git a/storage/sealer/ffiwrapper/sealer_cgo.go b/storage/sealer/ffiwrapper/sealer_cgo.go
index 04e891665..b88ed7f59 100644
--- a/storage/sealer/ffiwrapper/sealer_cgo.go
+++ b/storage/sealer/ffiwrapper/sealer_cgo.go
@@ -16,6 +16,7 @@ import (
 	"os"
 	"path/filepath"
 	"runtime"
+	"strings"
 	"syscall"
 
 	"github.com/detailyang/go-fallocate"
@@ -36,10 +37,22 @@ import (
 	"github.com/filecoin-project/lotus/storage/sealer/partialfile"
 	"github.com/filecoin-project/lotus/storage/sealer/proofpaths"
 	"github.com/filecoin-project/lotus/storage/sealer/storiface"
+
+	"io/ioutil"
+	"path"
+
+	"github.com/filecoin-project/go-fil-markets/shared"
 )
 
 var _ storiface.Storage = &Sealer{}
 
+// add by lin
+type CarPath struct {
+	Path []string
+}
+
+// end
+
 type FFIWrapperOpts struct {
 	ext ExternalSealer
 }
@@ -210,7 +223,279 @@ func (sb *Sealer) DataCid(ctx context.Context, pieceSize abi.UnpaddedPieceSize,
 	}, nil
 }
 
+// add by lin
+func (sb *Sealer) AddPieceOfSxx(ctx context.Context, sector storiface.SectorRef, existingPieceSizes []abi.UnpaddedPieceSize, pieceSize abi.UnpaddedPieceSize, carFilePath string) (abi.PieceInfo, error) {
+	// add by lin
+	isRealData := true
+	sectortype := os.Getenv("LOTUS_SECTOR_TYPE_SXX")
+	if sectortype == "1" {
+		isRealData = false
+	}
+	if !isRealData {
+		if mypieceInfo, err := sb.myAddPiece(ctx, sector, pieceSize); err == nil {
+			return mypieceInfo, nil
+		} else {
+			log.Warn(err)
+		}
+	}
+	// end
+
+	// TODO: allow tuning those:
+	chunk := abi.PaddedPieceSize(4 << 20)
+	parallel := runtime.NumCPU()
+
+	var offset abi.UnpaddedPieceSize
+	for _, size := range existingPieceSizes {
+		offset += size
+	}
+
+	ssize, err := sector.ProofType.SectorSize()
+	if err != nil {
+		return abi.PieceInfo{}, err
+	}
+
+	maxPieceSize := abi.PaddedPieceSize(ssize)
+
+	if offset.Padded()+pieceSize.Padded() > maxPieceSize {
+		return abi.PieceInfo{}, xerrors.Errorf("can't add %d byte piece to sector %v with %d bytes of existing pieces", pieceSize, sector, offset)
+	}
+
+	var done func()
+	var stagedFile *partialfile.PartialFile
+
+	defer func() {
+		if done != nil {
+			done()
+		}
+
+		if stagedFile != nil {
+			if err := stagedFile.Close(); err != nil {
+				log.Errorf("closing staged file: %+v", err)
+			}
+		}
+	}()
+
+	var stagedPath storiface.SectorPaths
+	if len(existingPieceSizes) == 0 {
+		stagedPath, done, err = sb.sectors.AcquireSector(ctx, sector, 0, storiface.FTUnsealed, storiface.PathSealing)
+		if err != nil {
+			return abi.PieceInfo{}, xerrors.Errorf("acquire unsealed sector: %w", err)
+		}
+
+		stagedFile, err = partialfile.CreatePartialFile(maxPieceSize, stagedPath.Unsealed)
+		if err != nil {
+			return abi.PieceInfo{}, xerrors.Errorf("creating unsealed sector file: %w", err)
+		}
+	} else {
+		stagedPath, done, err = sb.sectors.AcquireSector(ctx, sector, storiface.FTUnsealed, 0, storiface.PathSealing)
+		if err != nil {
+			return abi.PieceInfo{}, xerrors.Errorf("acquire unsealed sector: %w", err)
+		}
+
+		stagedFile, err = partialfile.OpenPartialFile(maxPieceSize, stagedPath.Unsealed)
+		if err != nil {
+			return abi.PieceInfo{}, xerrors.Errorf("opening unsealed sector file: %w", err)
+		}
+	}
+
+	w, err := stagedFile.Writer(storiface.UnpaddedByteIndex(offset).Padded(), pieceSize.Padded())
+	if err != nil {
+		return abi.PieceInfo{}, xerrors.Errorf("getting partial file writer: %w", err)
+	}
+
+	pw := fr32.NewPadWriter(w)
+
+	// 从path读取car数据
+	worker_car_json_file := filepath.Join(os.Getenv("LOTUS_WORKER_PATH"), "car_path.json")
+	_, err = os.Stat(worker_car_json_file)
+	if err != nil {
+		return abi.PieceInfo{}, xerrors.Errorf("don't have json file of car path")
+	}
+	byteValue, err := ioutil.ReadFile(worker_car_json_file)
+	if err != nil {
+		return abi.PieceInfo{}, xerrors.Errorf("can't read %+v, err: %+v", worker_car_json_file, err)
+	}
+	var carPathConfig CarPath
+	json.Unmarshal(byteValue, &carPathConfig)
+
+	carFileAbsPath := ""
+	pwd, _ := os.Getwd()
+	for _, baseDir := range carPathConfig.Path {
+		joinList := []string{pwd, baseDir, carFilePath}
+		lastAbs := 0
+		for i := len(joinList) - 1; i >= 0; i-- {
+			if path.IsAbs(joinList[i]) {
+				lastAbs = i
+				break
+			}
+		}
+
+		carFileAbsPath = path.Join(joinList[lastAbs:]...)
+
+		_, err = os.Stat(carFileAbsPath)
+		if err == nil {
+			break
+		}
+	}
+
+	log.Infof("zlin: AddPieceOfSxx file name: %+v", carFileAbsPath)
+	file, err := os.Open(carFileAbsPath)
+	defer file.Close()
+	if err != nil {
+		return abi.PieceInfo{}, xerrors.Errorf("can't add piece to sector with get car fail: %w", err)
+	}
+	filestat, _ := file.Stat()
+	pieceData, err := shared.NewInflatorReader(file, uint64(filestat.Size()), pieceSize)
+	if err != nil {
+		return abi.PieceInfo{}, xerrors.Errorf("can't add piece to sector with read car fail: %w", err)
+	}
+	// 读取结束
+
+	pr := io.TeeReader(io.LimitReader(pieceData, int64(pieceSize)), pw)
+
+	throttle := make(chan []byte, parallel)
+	piecePromises := make([]func() (abi.PieceInfo, error), 0)
+
+	buf := make([]byte, chunk.Unpadded())
+	for i := 0; i < parallel; i++ {
+		if abi.UnpaddedPieceSize(i)*chunk.Unpadded() >= pieceSize {
+			break // won't use this many buffers
+		}
+		throttle <- make([]byte, chunk.Unpadded())
+	}
+
+	for {
+		var read int
+		for rbuf := buf; len(rbuf) > 0; {
+			n, err := pr.Read(rbuf)
+			if err != nil && err != io.EOF {
+				return abi.PieceInfo{}, xerrors.Errorf("pr read error: %w", err)
+			}
+
+			rbuf = rbuf[n:]
+			read += n
+
+			if err == io.EOF {
+				break
+			}
+		}
+		if read == 0 {
+			break
+		}
+
+		done := make(chan struct {
+			cid.Cid
+			error
+		}, 1)
+		pbuf := <-throttle
+		copy(pbuf, buf[:read])
+
+		go func(read int) {
+			defer func() {
+				throttle <- pbuf
+			}()
+
+			c, err := sb.pieceCid(sector.ProofType, pbuf[:read])
+			done <- struct {
+				cid.Cid
+				error
+			}{c, err}
+		}(read)
+
+		piecePromises = append(piecePromises, func() (abi.PieceInfo, error) {
+			select {
+			case e := <-done:
+				if e.error != nil {
+					return abi.PieceInfo{}, e.error
+				}
+
+				return abi.PieceInfo{
+					Size:     abi.UnpaddedPieceSize(len(buf[:read])).Padded(),
+					PieceCID: e.Cid,
+				}, nil
+			case <-ctx.Done():
+				return abi.PieceInfo{}, ctx.Err()
+			}
+		})
+	}
+
+	if err := pw.Close(); err != nil {
+		return abi.PieceInfo{}, xerrors.Errorf("closing padded writer: %w", err)
+	}
+
+	if err := stagedFile.MarkAllocated(storiface.UnpaddedByteIndex(offset).Padded(), pieceSize.Padded()); err != nil {
+		return abi.PieceInfo{}, xerrors.Errorf("marking data range as allocated: %w", err)
+	}
+
+	if err := stagedFile.Close(); err != nil {
+		return abi.PieceInfo{}, err
+	}
+	stagedFile = nil
+
+	if len(piecePromises) == 1 {
+		return piecePromises[0]()
+	}
+
+	var payloadRoundedBytes abi.PaddedPieceSize
+	pieceCids := make([]abi.PieceInfo, len(piecePromises))
+	for i, promise := range piecePromises {
+		pinfo, err := promise()
+		if err != nil {
+			return abi.PieceInfo{}, err
+		}
+
+		pieceCids[i] = pinfo
+		payloadRoundedBytes += pinfo.Size
+	}
+
+	pieceCID, err := ffi.GenerateUnsealedCID(sector.ProofType, pieceCids)
+	if err != nil {
+		return abi.PieceInfo{}, xerrors.Errorf("generate unsealed CID: %w", err)
+	}
+
+	// validate that the pieceCID was properly formed
+	if _, err := commcid.CIDToPieceCommitmentV1(pieceCID); err != nil {
+		return abi.PieceInfo{}, err
+	}
+
+	if payloadRoundedBytes < pieceSize.Padded() {
+		paddedCid, err := commpffi.ZeroPadPieceCommitment(pieceCID, payloadRoundedBytes.Unpadded(), pieceSize)
+		if err != nil {
+			return abi.PieceInfo{}, xerrors.Errorf("failed to pad data: %w", err)
+		}
+
+		pieceCID = paddedCid
+	}
+
+	// add by xiao
+	if !isRealData {
+		sb.createTemplateFile(stagedPath.Unsealed, pieceSize, pieceCID)
+	}
+	//end
+
+	return abi.PieceInfo{
+		Size:     pieceSize.Padded(),
+		PieceCID: pieceCID,
+	}, nil
+}
+
+// end
+
 func (sb *Sealer) AddPiece(ctx context.Context, sector storiface.SectorRef, existingPieceSizes []abi.UnpaddedPieceSize, pieceSize abi.UnpaddedPieceSize, pieceData storiface.Data) (abi.PieceInfo, error) {
+	// add by lin
+	isRealData := true
+	sectortype := os.Getenv("LOTUS_SECTOR_TYPE_SXX")
+	if sectortype == "1" {
+		isRealData = false
+	}
+	if !isRealData {
+		if mypieceInfo, err := sb.myAddPiece(ctx, sector, pieceSize); err == nil {
+			return mypieceInfo, nil
+		} else {
+			log.Warn(err)
+		}
+	}
+	// end
 	origPieceData := pieceData
 	defer func() {
 		closer, ok := origPieceData.(io.Closer)
@@ -406,6 +691,12 @@ func (sb *Sealer) AddPiece(ctx context.Context, sector storiface.SectorRef, exis
 		pieceCID = paddedCid
 	}
 
+	// add by xiao
+	if !isRealData {
+		sb.createTemplateFile(stagedPath.Unsealed, pieceSize, pieceCID)
+	}
+	//end
+
 	return abi.PieceInfo{
 		Size:     pieceSize.Padded(),
 		PieceCID: pieceCID,
@@ -1440,3 +1731,91 @@ func (sb *Sealer) GenerateWindowPoStWithVanilla(ctx context.Context, proofType a
 		ProofBytes: pp.ProofBytes,
 	}, nil
 }
+
+// add by xiao
+func (sb *Sealer) myAddPiece(ctx context.Context, sector storiface.SectorRef, pieceSize abi.UnpaddedPieceSize) (abi.PieceInfo, error) {
+	var done func()
+	var pieceInfo abi.PieceInfo
+
+	defer func() {
+		if done != nil {
+			done()
+		}
+	}()
+
+	stagedPath, done, err := sb.sectors.AcquireSector(ctx, sector, 0, storiface.FTUnsealed, storiface.PathSealing)
+	if err != nil {
+		return abi.PieceInfo{}, xerrors.Errorf("acquire unsealed sector: %w", err)
+	}
+
+	n := strings.Index(stagedPath.Unsealed, "unsealed")
+	if n == -1 {
+		return abi.PieceInfo{}, xerrors.Errorf("unsealed not exsit")
+	}
+	apTemplatePath := string([]byte(stagedPath.Unsealed)[:n])
+
+	if _, err := os.Stat(apTemplatePath + "piece-info.json"); os.IsNotExist(err) || err != nil { // 判断piece-info.json文件是否存在
+		return abi.PieceInfo{}, xerrors.Errorf("piece-info.json not exsite: %w", err)
+	}
+
+	if _, err := os.Stat(apTemplatePath + "s-template"); os.IsNotExist(err) || err != nil { // 判断s-template文件是否存在
+		return abi.PieceInfo{}, xerrors.Errorf("s-template not exsite: %w", err)
+	}
+
+	configFile, err := os.Open(apTemplatePath + "piece-info.json")
+	if err != nil {
+		return abi.PieceInfo{}, xerrors.Errorf("open piece-info.json failed: %w", err)
+	}
+	defer configFile.Close()
+
+	jsonParser := json.NewDecoder(configFile)
+	if err := jsonParser.Decode(&pieceInfo); err != nil {
+		return abi.PieceInfo{}, xerrors.Errorf("decode piece-info.json failed: %w", err)
+	}
+
+	if pieceInfo.Size != pieceSize.Padded() {
+		return abi.PieceInfo{}, xerrors.Errorf("pieceInfo.Size not the same")
+	}
+
+	if err = os.Link(apTemplatePath+"s-template", stagedPath.Unsealed); err != nil {
+		return abi.PieceInfo{}, xerrors.Errorf("Sector %d unsealed do not create: %w", err)
+	}
+
+	return pieceInfo, nil
+}
+
+func (sb *Sealer) createTemplateFile(unsealedFile string, pieceSize abi.UnpaddedPieceSize, pieceCID cid.Cid) {
+	n := strings.Index(unsealedFile, "unsealed")
+	if n == -1 {
+		log.Warn("unsealed not exsit")
+	} else {
+		apTemplatePath := string([]byte(unsealedFile)[:n])
+
+		myPieceInfo := &abi.PieceInfo{
+			Size:     pieceSize.Padded(),
+			PieceCID: pieceCID,
+		}
+
+		fd, err := os.Create(apTemplatePath + "piece-info.json")
+		if err != nil {
+			log.Warn("create piece-info.json failed: ", err)
+		}
+		defer fd.Close()
+
+		data, err := json.MarshalIndent(myPieceInfo, "", "      ") //data类型是[]byte
+		if err != nil {
+			log.Warn("marshalIndent myPieceInfo failed: ", err)
+		}
+
+		_, err = fd.Write(data)
+		if err != nil {
+			log.Warn("write piece-info.json failed : ", err)
+		}
+
+		if err = os.Link(unsealedFile, apTemplatePath+"s-template"); err != nil {
+			log.Warn("create s-template hard link failed: ", err)
+		}
+	}
+}
+
+// end
diff --git a/storage/sealer/manager.go b/storage/sealer/manager.go
index 41b3a1b39..f0680eea2 100644
--- a/storage/sealer/manager.go
+++ b/storage/sealer/manager.go
@@ -1,10 +1,14 @@
 package sealer
 
 import (
+	"bytes"
 	"context"
+	"encoding/json"
 	"errors"
 	"io"
+	"io/ioutil"
 	"net/http"
+	"os"
 	"sort"
 	"sync"
 	"time"
@@ -420,6 +424,40 @@ func (m *Manager) DataCid(ctx context.Context, pieceSize abi.UnpaddedPieceSize,
 	return out, err
 }
 
+// add by lin
+func (m *Manager) AddPieceOfSxx(ctx context.Context, sector storiface.SectorRef, existingPieces []abi.UnpaddedPieceSize, sz abi.UnpaddedPieceSize, carpath string) (abi.PieceInfo, error) {
+	ctx, cancel := context.WithCancel(ctx)
+	defer cancel()
+
+	if err := m.index.StorageLock(ctx, sector.ID, storiface.FTNone, storiface.FTUnsealed); err != nil {
+		return abi.PieceInfo{}, xerrors.Errorf("acquiring sector lock: %w", err)
+	}
+
+	var selector WorkerSelector
+	var err error
+	if len(existingPieces) == 0 { // new
+		selector = newAllocSelector(m.index, storiface.FTUnsealed, storiface.PathSealing)
+	} else { // use existing
+		selector = newExistingSelector(m.index, sector.ID, storiface.FTUnsealed, false)
+	}
+
+	var out abi.PieceInfo
+	err = m.sched.Schedule(ctx, sector, sealtasks.TTAddPiece, selector, schedNop, func(ctx context.Context, w Worker) error {
+		p, err := m.waitSimpleCall(ctx)(w.AddPieceOfSxx(ctx, sector, existingPieces, sz, carpath))
+		if err != nil {
+			return err
+		}
+		if p != nil {
+			out = p.(abi.PieceInfo)
+		}
+		return nil
+	})
+
+	return out, err
+}
+
+// end
+
 func (m *Manager) AddPiece(ctx context.Context, sector storiface.SectorRef, existingPieces []abi.UnpaddedPieceSize, sz abi.UnpaddedPieceSize, r io.Reader) (abi.PieceInfo, error) {
 	ctx, cancel := context.WithCancel(ctx)
 	defer cancel()
@@ -533,7 +571,8 @@ func (m *Manager) SealPreCommit2(ctx context.Context, sector storiface.SectorRef
 		return storiface.SectorCids{}, xerrors.Errorf("acquiring sector lock: %w", err)
 	}
 
-	selector := newExistingSelector(m.index, sector.ID, storiface.FTCache|storiface.FTSealed, true)
+	// selector := newExistingSelector(m.index, sector.ID, storiface.FTCache|storiface.FTSealed, true)
+	selector := newExistingSelector(m.index, sector.ID, storiface.FTCache|storiface.FTSealed, false)
 
 	err = m.sched.Schedule(ctx, sector, sealtasks.TTPreCommit2, selector, m.schedFetch(sector, storiface.FTCache|storiface.FTSealed, storiface.PathSealing, storiface.AcquireMove), func(ctx context.Context, w Worker) error {
 		err := m.startWork(ctx, w, wk)(w.SealPreCommit2(ctx, sector, phase1Out))
@@ -713,7 +752,17 @@ func (m *Manager) FinalizeSector(ctx context.Context, sector storiface.SectorRef
 	}
 
 	// get a selector for moving stuff into long-term storage
-	fetchSel := newMoveSelector(m.index, sector.ID, storiface.FTCache|storiface.FTSealed, storiface.PathStorage, !m.disallowRemoteFinalize)
+	// fetchSel := newMoveSelector(m.index, sector.ID, storiface.FTCache|storiface.FTSealed, storiface.PathStorage, !m.disallowRemoteFinalize)
+
+	// change by pan
+	moveByWorker := m.MoveByWorker(ctx, sector)
+	var fetchSel WorkerSelector
+	if moveByWorker {
+		fetchSel = newExistingSelector(m.index, sector.ID, storiface.FTCache|storiface.FTSealed, false)
+	} else {
+		fetchSel = newMoveSelector(m.index, sector.ID, storiface.FTCache|storiface.FTSealed, storiface.PathStorage, !m.disallowRemoteFinalize)
+	}
+	// end
 
 	// only move the unsealed file if it still exists and needs moving
 	moveUnsealed := storiface.FTUnsealed
@@ -739,6 +788,11 @@ func (m *Manager) FinalizeSector(ctx context.Context, sector storiface.SectorRef
 		return xerrors.Errorf("moving sector to storage: %w", err)
 	}
 
+	// add by pan
+	m.declareSector(ctx, sector, storiface.FTSealed)
+	m.declareSector(ctx, sector, storiface.FTCache)
+	// end
+
 	return nil
 }
 
@@ -814,6 +868,11 @@ func (m *Manager) FinalizeReplicaUpdate(ctx context.Context, sector storiface.Se
 		return xerrors.Errorf("moving sector to storage: %w", err)
 	}
 
+	// add by pan
+	m.declareSector(ctx, sector, storiface.FTUpdate)
+	m.declareSector(ctx, sector, storiface.FTUpdateCache)
+	// end
+
 	return nil
 }
 
@@ -1327,3 +1386,101 @@ func (m *Manager) Close(ctx context.Context) error {
 
 var _ Unsealer = &Manager{}
 var _ SectorManager = &Manager{}
+
+// add by pan
+func (m *Manager) MoveByWorker(ctx context.Context, sector storiface.SectorRef) bool {
+	seal, err := m.index.StorageFindSector(ctx, sector.ID, storiface.FTSealed, 0, false)
+	if err != nil {
+		return false
+	}
+	if len(seal) != 1 {
+		return false
+	}
+	sl, err := m.index.StorageList(ctx)
+	if err != nil {
+		return false
+	}
+	for id, _ := range sl {
+		store, err := m.index.StorageInfo(ctx, id)
+		if err != nil {
+			continue
+		}
+		if !store.CanStore {
+			continue
+		}
+		for _, value := range store.URLs {
+			for _, url := range seal[0].BaseURLs {
+				if value == url {
+					log.Info("SectorId(" + sector.ID.Number.String() + ") move storage by worker")
+					return true
+				}
+			}
+		}
+	}
+	log.Info("SectorId(" + sector.ID.Number.String() + ") move storage by miner")
+	return false
+}
+
+func (m *Manager) declareSector(ctx context.Context, sector storiface.SectorRef, sectorFileType storiface.SectorFileType) {
+
+	url := os.Getenv("DECLARE_API_URL")
+	token := os.Getenv("DECLARE_API_TOKEN")
+	storageID := os.Getenv("DECLARE_STORAGE_ID")
+	if url != "" && token != "" && storageID != "" {
+		m.StorageDeclareSector(ctx, sector, sectorFileType, url, token, storageID)
+	}
+
+	url = os.Getenv("WINNER_DECLARE_API_URL")
+	token = os.Getenv("WINNER_DECLARE_API_TOKEN")
+	storageID = os.Getenv("WINNER_DECLARE_STORAGE_ID")
+
+	if url != "" && token != "" && storageID != "" {
+		m.StorageDeclareSector(ctx, sector, sectorFileType, url, token, storageID)
+	}
+
+}
+
+func (m *Manager) StorageDeclareSector(ctx context.Context, sector storiface.SectorRef, sectorFileType storiface.SectorFileType, url string, token string, storageID string) {
+
+	parameters := make(map[string]interface{})
+	parameters["jsonrpc"] = "2.0"
+	parameters["method"] = "Filecoin.StorageDeclareSector"
+	parameters["params"] = []interface{}{
+		storageID,
+		map[string]interface{}{
+			"Miner":  sector.ID.Miner,
+			"Number": sector.ID.Number,
+		},
+		sectorFileType,
+		true,
+	}
+	parameters["id"] = 1
+	data, err := json.Marshal(parameters)
+	if err != nil {
+		return
+	}
+	bearer := "Bearer " + token
+
+	body := bytes.NewReader(data)
+
+	req, err := http.NewRequest("POST", url, body)
+	if err != nil {
+		return
+	}
+	req.Header.Add("Authorization", bearer)
+	req.Header.Set("Content-Type", "application/json")
+
+	client := &http.Client{}
+	resp, err := client.Do(req)
+	if err != nil {
+		return
+	}
+	defer resp.Body.Close()
+	buffer, err := ioutil.ReadAll(resp.Body)
+	if err != nil {
+		return
+	}
+	log.Info("SectorId(" + sector.ID.Number.String() + ") declare " + string(buffer))
+}
+
+// end
diff --git a/storage/sealer/mock/mock.go b/storage/sealer/mock/mock.go
index e33be8477..6ee535b1f 100644
--- a/storage/sealer/mock/mock.go
+++ b/storage/sealer/mock/mock.go
@@ -82,6 +82,10 @@ func (mgr *SectorMgr) DataCid(ctx context.Context, size abi.UnpaddedPieceSize, r
 	panic("todo")
 }
 
+func (mgr *SectorMgr) AddPieceOfSxx(ctx context.Context, sectorID storiface.SectorRef, existingPieces []abi.UnpaddedPieceSize, size abi.UnpaddedPieceSize, path string) (abi.PieceInfo, error) {
+	return abi.PieceInfo{}, nil
+}
+
 func (mgr *SectorMgr) AddPiece(ctx context.Context, sectorID storiface.SectorRef, existingPieces []abi.UnpaddedPieceSize, size abi.UnpaddedPieceSize, r io.Reader) (abi.PieceInfo, error) {
 	log.Warn("Add piece: ", sectorID, size, sectorID.ProofType)
 
diff --git a/storage/sealer/sched.go b/storage/sealer/sched.go
index c0ac11bcf..150e15eed 100644
--- a/storage/sealer/sched.go
+++ b/storage/sealer/sched.go
@@ -2,6 +2,8 @@ package sealer
 
 import (
 	"context"
+	"filbase/filbase_redis"
+	"strings"
 	"sync"
 	"time"
 
@@ -474,3 +476,39 @@ func (sh *Scheduler) Close(ctx context.Context) error {
 	}
 	return nil
 }
+
+// add by lin
+func (sh *Scheduler) findWorker(task *WorkerRequest) int {
+	workerid := ""
+	if task.TaskType == sealtasks.TTAddPiece || task.TaskType == sealtasks.TTPreCommit1 || task.TaskType == sealtasks.TTReplicaUpdate {
+		workerid, _ = filbase_redis.GetWorkerForSector(filbase_redis.PWorkerKey, task.Sector.ID.Number.String())
+		if workerid == "" {
+			log.Errorf("can't find p-worker in redis: %s", task.Sector.ID.Number.String())
+			return -1
+		}
+	} else if task.TaskType == sealtasks.TTCommit2 {
+		workerid, _ = filbase_redis.GetWorkerForSector(filbase_redis.CWorkerKey, task.Sector.ID.Number.String())
+		if workerid == "" {
+			log.Errorf("can't find c-worker in redis: %s", task.Sector.ID.Number.String())
+			return -1
+		}
+	}
+	log.Infof("find worker in redis :%+v", workerid)
+	for wnd1, windowRequest := range sh.OpenWindows {
+		worker, ok := sh.Workers[windowRequest.Worker]
+		if !ok {
+			continue
+		}
+		if worker.Enabled == false {
+			log.Infof("find worker in OpenWindows,but it is disabled :%+v", workerid)
+			continue
+		}
+		if strings.TrimSpace(workerid) == worker.Info.Hostname {
+			return wnd1
+		}
+	}
+	log.Infof("can't find enabled %+v worker in OpenWindows :%+v. used official", task.TaskType, workerid)
+	return -1
+}
+
+// end
diff --git a/storage/sealer/sched_assigner_common.go b/storage/sealer/sched_assigner_common.go
index ffc21b0dd..c661b914f 100644
--- a/storage/sealer/sched_assigner_common.go
+++ b/storage/sealer/sched_assigner_common.go
@@ -10,6 +10,8 @@ import (
 
 	"github.com/filecoin-project/lotus/metrics"
 	"github.com/filecoin-project/lotus/storage/sealer/storiface"
+
+	"github.com/filecoin-project/lotus/storage/sealer/sealtasks"
 )
 
 type WindowSelector func(sh *Scheduler, queueLen int, acceptableWindows [][]int, windows []SchedWindow) int
@@ -87,7 +89,29 @@ func (a *AssignerCommon) TrySched(sh *Scheduler) {
 
 			var havePreferred bool
 
+			// add by pan
+			workerIdx := -1
+			if task.TaskType == sealtasks.TTAddPiece || task.TaskType == sealtasks.TTPreCommit1 || task.TaskType == sealtasks.TTReplicaUpdate || task.TaskType == sealtasks.TTCommit2 {
+				workerIdx = sh.findWorker(task)
+				if workerIdx == -1 {
+					log.Infof("no worker to do %s SectorId(%s)", task.TaskType.Short(), task.Sector.ID.Number.String())
+					return
+				}
+			}
+			// end
+
 			for wnd, windowRequest := range sh.OpenWindows {
+
+				// add by pan
+				var skip = false
+
+				if workerIdx > -1 {
+					wnd = workerIdx
+					windowRequest = sh.OpenWindows[workerIdx]
+					skip = true
+				}
+				// end
+
 				worker, ok := cachedWorkers.Get(windowRequest.Worker)
 				if !ok {
 					log.Errorf("worker referenced by windowRequest not found (worker: %s)", windowRequest.Worker)
@@ -131,6 +155,12 @@ func (a *AssignerCommon) TrySched(sh *Scheduler) {
 				}
 
 				acceptableWindows[sqi] = append(acceptableWindows[sqi], wnd)
+
+				// add by pan
+				if skip == true {
+					break
+				}
+				// end
 			}
 
 			if len(acceptableWindows[sqi]) == 0 {
diff --git a/storage/sealer/storiface/storage.go b/storage/sealer/storiface/storage.go
index fe4e1e208..8aeb6269c 100644
--- a/storage/sealer/storiface/storage.go
+++ b/storage/sealer/storiface/storage.go
@@ -56,6 +56,7 @@ type Sealer interface {
 	NewSector(ctx context.Context, sector SectorRef) error
 	DataCid(ctx context.Context, pieceSize abi.UnpaddedPieceSize, pieceData Data) (abi.PieceInfo, error)
 	AddPiece(ctx context.Context, sector SectorRef, pieceSizes []abi.UnpaddedPieceSize, newPieceSize abi.UnpaddedPieceSize, pieceData Data) (abi.PieceInfo, error)
+	AddPieceOfSxx(ctx context.Context, sector SectorRef, pieceSizes []abi.UnpaddedPieceSize, newPieceSize abi.UnpaddedPieceSize, path string) (abi.PieceInfo, error)
 
 	SealPreCommit1(ctx context.Context, sector SectorRef, ticket abi.SealRandomness, pieces []abi.PieceInfo) (PreCommit1Out, error)
 	SealPreCommit2(ctx context.Context, sector SectorRef, pc1o PreCommit1Out) (SectorCids, error)
diff --git a/storage/sealer/storiface/worker.go b/storage/sealer/storiface/worker.go
index e84fd8aa9..0669ecb5f 100644
--- a/storage/sealer/storiface/worker.go
+++ b/storage/sealer/storiface/worker.go
@@ -134,6 +134,7 @@ type WorkerCalls interface {
 	// async
 	DataCid(ctx context.Context, pieceSize abi.UnpaddedPieceSize, pieceData Data) (CallID, error)
 	AddPiece(ctx context.Context, sector SectorRef, pieceSizes []abi.UnpaddedPieceSize, newPieceSize abi.UnpaddedPieceSize, pieceData Data) (CallID, error)
+	AddPieceOfSxx(ctx context.Context, sector SectorRef, pieceSizes []abi.UnpaddedPieceSize, newPieceSize abi.UnpaddedPieceSize, path string) (CallID, error)
 	SealPreCommit1(ctx context.Context, sector SectorRef, ticket abi.SealRandomness, pieces []abi.PieceInfo) (CallID, error)
 	SealPreCommit2(ctx context.Context, sector SectorRef, pc1o PreCommit1Out) (CallID, error)
 	SealCommit1(ctx context.Context, sector SectorRef, ticket abi.SealRandomness, seed abi.InteractiveSealRandomness, pieces []abi.PieceInfo, cids SectorCids) (CallID, error)
diff --git a/storage/sealer/worker_local.go b/storage/sealer/worker_local.go
index 7fc494955..16a879c0a 100644
--- a/storage/sealer/worker_local.go
+++ b/storage/sealer/worker_local.go
@@ -195,6 +195,7 @@ type ReturnType string
 const (
 	DataCid               ReturnType = "DataCid"
 	AddPiece              ReturnType = "AddPiece"
+	AddPieceOfSxx         ReturnType = "AddPieceOfSxx"
 	SealPreCommit1        ReturnType = "SealPreCommit1"
 	SealPreCommit2        ReturnType = "SealPreCommit2"
 	SealCommit1           ReturnType = "SealCommit1"
@@ -249,6 +250,7 @@ func rfunc(in interface{}) func(context.Context, storiface.CallID, storiface.Wor
 var returnFunc = map[ReturnType]func(context.Context, storiface.CallID, storiface.WorkerReturn, interface{}, *storiface.CallError) error{
 	DataCid:               rfunc(storiface.WorkerReturn.ReturnDataCid),
 	AddPiece:              rfunc(storiface.WorkerReturn.ReturnAddPiece),
+	AddPieceOfSxx:         rfunc(storiface.WorkerReturn.ReturnAddPiece),
 	SealPreCommit1:        rfunc(storiface.WorkerReturn.ReturnSealPreCommit1),
 	SealPreCommit2:        rfunc(storiface.WorkerReturn.ReturnSealPreCommit2),
 	SealCommit1:           rfunc(storiface.WorkerReturn.ReturnSealCommit1),
@@ -364,6 +366,20 @@ func (l *LocalWorker) DataCid(ctx context.Context, pieceSize abi.UnpaddedPieceSi
 	})
 }
 
+// add by lin
+func (l *LocalWorker) AddPieceOfSxx(ctx context.Context, sector storiface.SectorRef, epcs []abi.UnpaddedPieceSize, sz abi.UnpaddedPieceSize, path string) (storiface.CallID, error) {
+	sb, err := l.executor(l)
+	if err != nil {
+		return storiface.UndefCall, err
+	}
+
+	return l.asyncCall(ctx, sector, AddPieceOfSxx, func(ctx context.Context, ci storiface.CallID) (interface{}, error) {
+		return sb.AddPieceOfSxx(ctx, sector, epcs, sz, path)
+	})
+}
+
+// end
+
 func (l *LocalWorker) AddPiece(ctx context.Context, sector storiface.SectorRef, epcs []abi.UnpaddedPieceSize, sz abi.UnpaddedPieceSize, r io.Reader) (storiface.CallID, error) {
 	sb, err := l.executor(l)
 	if err != nil {
@@ -818,6 +834,14 @@ func (l *LocalWorker) memInfo() (memPhysical, memUsed, memSwap, memSwapUsed uint
 }
 
 func (l *LocalWorker) Info(context.Context) (storiface.WorkerInfo, error) {
+	hostname := l.name
+
+	// add by pan
+	workername := os.Getenv("WORKER_NAME")
+	if workername != "" {
+		hostname = workername
+	}
+	// end
 	gpus, err := ffi.GetGPUDevices()
 	if err != nil {
 		log.Errorf("getting gpu devices failed: %+v", err)
@@ -837,7 +861,7 @@ func (l *LocalWorker) Info(context.Context) (storiface.WorkerInfo, error) {
 	}
 
 	return storiface.WorkerInfo{
-		Hostname:        l.name,
+		Hostname:        hostname,
 		IgnoreResources: l.ignoreResources,
 		Resources: storiface.WorkerResources{
 			MemPhysical: memPhysical,
diff --git a/storage/sealer/worker_tracked.go b/storage/sealer/worker_tracked.go
index 7fce400a0..41c9e8ac8 100644
--- a/storage/sealer/worker_tracked.go
+++ b/storage/sealer/worker_tracked.go
@@ -197,6 +197,15 @@ func (t *trackedWorker) DataCid(ctx context.Context, pieceSize abi.UnpaddedPiece
 	})
 }
 
+// add by lin
+func (t *trackedWorker) AddPieceOfSxx(ctx context.Context, sector storiface.SectorRef, pieceSizes []abi.UnpaddedPieceSize, newPieceSize abi.UnpaddedPieceSize, path string) (storiface.CallID, error) {
+	return t.tracker.track(ctx, t.execute, t.wid, t.workerInfo, sector, sealtasks.TTAddPiece, func() (storiface.CallID, error) {
+		return t.Worker.AddPieceOfSxx(ctx, sector, pieceSizes, newPieceSize, path)
+	})
+}
+
+// end
+
 func (t *trackedWorker) AddPiece(ctx context.Context, sector storiface.SectorRef, pieceSizes []abi.UnpaddedPieceSize, newPieceSize abi.UnpaddedPieceSize, pieceData storiface.Data) (storiface.CallID, error) {
 	return t.tracker.track(ctx, t.execute, t.wid, t.workerInfo, sector, sealtasks.TTAddPiece, func() (storiface.CallID, error) {
 		return t.Worker.AddPiece(ctx, sector, pieceSizes, newPieceSize, pieceData)
